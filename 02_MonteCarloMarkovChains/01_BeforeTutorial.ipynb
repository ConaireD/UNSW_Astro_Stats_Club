{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde66530-3cd5-4122-ab5c-107843a6ace4",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h1>Notebook 1: Monte Carlo Markov Chains Background</h1>\n",
    "\n",
    "<h2>Structure</h2>\n",
    "\n",
    "| Part | Topic | Type |\n",
    "|:----:|-------|------|\n",
    "| 1 | Recap: Where We Left Off | Conceptual |\n",
    "| 2 | Monte Carlo Ingtegration | Conceptual + Code |\n",
    "| 3 | Markov Chains | Conceptual + Code |\n",
    "| 4 | The Metropolist Algorithm | Technical |\n",
    "| - | Exercise: Fitting a Radial Velocity Curve| Hands-on |\n",
    "| - | Exercise: Increasing `n_obs` | Hands-on |\n",
    "| - | Proposal Width Tuning | Technical |\n",
    "| 5 | Detailed Balance & Ergocity | Theoretical |\n",
    "| 6 | Hamiltonian Monte Carlo & NUTS | Conceptual |\n",
    "| - | NumPyro Demonstartion | Practical |\n",
    "\n",
    "\n",
    "<h2>Preamble</h2>\n",
    "\n",
    "- What this covers\n",
    "- Won't be required to write code, only run it\n",
    "- An installation check will be performed\n",
    "- Reading Guide: Sections marked with \"üèõÔ∏è **Historical Aside**\" are anecdotes and context. They are completely skippable, but can be fun.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3917a5-a5cb-4ce0-ae05-40087beb453e",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h1>Recap: Where We Left Off</h1>\n",
    "\n",
    "In previous tutorials, we defined Bayes Theorem:\n",
    "$$P(\\theta \\mid D) = \\frac{\\mathcal{L}(\\theta) \\, \\pi(\\theta)}{\\mathcal{Z}}$$\n",
    "Recall that each of the are:\n",
    "- $P(\\theta|D)$ - The posterior, i.e. what we believe about our parameters *after* seeing the data.\n",
    "- $\\mathcal{L}(\\theta)$ - The likelihood, i.e. the probability of seeing the data given a particular set of parameters (the physics and the noise).\n",
    "- $\\pi(\\theta)$ - The prior, i.e. what we believe about our parameters *before* seeing the data\n",
    "- $\\mathcal{Z}$ - The evidence, i.e. the total probability of observing your data, averaged over all parameter values weighted by the prior. In practice, treated as a normalisation constant.\n",
    "\n",
    "The nice thing about Bayes theorem, is that if we only care about parameter estimation (and not model comparison), we can treat the evidence as a normalisation constant and drop it, leaving:\n",
    "\n",
    "$$P(\\theta \\mid D) \\propto \\mathcal{L}(\\theta) \\, \\pi(\\theta)$$\n",
    "\n",
    "If you do care about model comparison, go back to the Nested Sampling notebook.\n",
    "\n",
    "In the Bayes 101 notebook, we fit a model to a spectral line by doing a grid search. This model had 4 parameters, we fixed two of them, and tested 250 values each for the other two parameters. This meant, that in total, we tested $250^2 = 62,500$ parameter combinations. If we didn't fix the other two, we would have had to test $250^4 \\approx 3.9$ billion parameter combinations. Obviously this is way too many to check. This problem is known as the curse of dimensionality. The basic problem is that high dimensional spaces have a lot of volume, most of which we don't care about. Let's see this in practice by using Monte Carlo methods\n",
    "\n",
    "-----------\n",
    "\n",
    "# üèõÔ∏è Historical Aside 1: Monte Carlo\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/MonteCarlo.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "    <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "    Left: A poster depicting the facade of the Monte Carlo Casino at sunset, by Mario Borgoni, c. 1910. Right: 'Souvenir de Monte Carlo' postcard, c. late 1800s, featuring a roulette wheel, and a lady on a donkey, likely a depiction of \"lady luck\".\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "### Name:\n",
    "\n",
    "Monte Carlo is a region within the city state of Monaco (near the French and Italian border). The Casino de Monte-Carlo was opened in 1863 to save the state from bankruptcy. The casino was so successful that income tax in Monaco was abolishd in 1869. It is likely the most famous casino in the world, and is the casino that inspired the casino in the James Bond novel and movie \"Casino Royale\".\n",
    "\n",
    "### Connection to Statistics:\n",
    "Like suprisingly many physics and statistics inventions, Monte Carlo methods origniated during the Manhatten Project (i.e. the nuclear bomb project) at Los Alamos. The Monte Carlo method was invented by Stanislaw Ulam and later formalised with the help of John von Neumann.\n",
    "\n",
    "#### Stanislaw Ulam\n",
    "\n",
    "Stanislaw Ulam was a Polish-Born (later American) mathematician. He and his brother left Poland to the USA on a voyage funded by his father and uncle. Eleven days after departure, the Nazis had invaded Poland which they took over within two months. Within two years, most of his family was murdered during the Holocaust. \n",
    "In 1943, he (may have) asked John von Neumann (who he had met several years earlier in Warsaw) to find him a war job. In October, he was sent an invitation to join an unidentified project in New Mexico. At the time, he was working at the University of Wisconsin-Madison. As he knew little of New Mexico, he checked out a New Mexico guide book from the university library. In the checkout card inside the guide book, the names of several of his colleagues appeared, all of whom had disappeared to work on the Manhatten Project.\n",
    "\n",
    "In 1946, he suffered from encephalitis -- a severe, life-threatening inflammation of the brain. This temporarily led to cognitive impairment (difficulty with mathematics, memory issues, etc). During his recovery, he had to relearn basic mathematics. While recovering, he played the solo card game solitare frequently and obsessively. While doing so, he started to wonder about the probability of a successful game. Rather than doing difficult combinatorial analysis, he realised that brute-force random sampling would be easier. This is where the Monte-Carlo method originates from. Allegedly, Nicholas Metropolis coined the name Monte-Carlo after Ulams fathers gambling problem and the name stuck. \n",
    "\n",
    "Unlike many of his Manhatten project colleagues, he was neither a nuclear hawk nor dove. Perhaps the reason that he did not become a dove was because the project was ostenstibly started in order to defeat the Nazis (who murdered most of his family), and not the Japanese. He did later support anti-nuclear testing treaties.\n",
    "\n",
    "----------------\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3a942-c501-401b-a843-f5343220621b",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "# Estimating $\\pi$ using Monte Carlo Methods\n",
    "\n",
    "The core idea is simple: *If computing something analytical is hard, throw random numbers at it and count.*\n",
    "\n",
    "This is a classic example that uses random sampling to estimate the value of $\\pi$. You likely have done this in your first computational physics class. \n",
    "\n",
    "Consider a square with a sidelength 2, centred at the origin (so $x,y \\in [-1,1]$), with a circled inscribed within it. \n",
    "- The area of the square: $A_\\text{square} = 2 \\times 2 = 4$\n",
    "- The area of the square: $A_\\text{circle} = \\pi r^2 = \\pi$\n",
    "\n",
    "The ratio of areas is then:\n",
    "\n",
    "$$ \\frac{A_\\text{circle}}{A_\\text{square}} = \\frac{\\pi}{4} $$\n",
    "\n",
    "We will (uniformly) randomly sample points on a two-dimensional plane with limits of [-1, 1], and we will count the number of points that land within a circle of radius 1. If we assume that the number of points within the circle and outside the circle are proportional to the respective areas (which uniform sampling guarantees in expectation), then the fraction of points landing inside the circle convergess to the fraction of the areas:\n",
    "\n",
    "$$ \\frac{N_\\text{inside}}{N_\\text{total}} \\xrightarrow{N \\to \\infty} \\frac{A_\\text{circle}}{A_\\text{square}} = \\frac{\\pi}{4}$$\n",
    "\n",
    "Rearranging, we get:\n",
    "\n",
    "$$ \\pi \\approx 4 \\times \\frac{N_\\text{inside}}{N_\\text{total}}$$\n",
    "</div>\n",
    "\n",
    "## Define the Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8f9dd-bec5-4eb7-a7f1-e1b26125edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import gamma\n",
    "from scipy.stats import chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7c958-b504-4f88-91f1-3cf70e9cc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Circle\n",
    "t = np.linspace(0,2*np.pi, 360)\n",
    "circ_x = np.cos(t)\n",
    "circ_y = np.sin(t)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.plot(circ_x, circ_y, ls = '--')\n",
    "plt.axis('equal')\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e60a1-2209-4524-974a-ab3096a11ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "np.random.seed(161)\n",
    "\n",
    "# Define arrays to keep track of things\n",
    "x_samples = []\n",
    "y_samples = []\n",
    "inside_mask = []\n",
    "running_pi_estimate = []\n",
    "\n",
    "num_samples = 10000\n",
    "plot_idxs = [10, 100, 1000, 5000, 10000]\n",
    "\n",
    "\n",
    "# note this is not an efficient implementation\n",
    "for i in tqdm(range(num_samples)):\n",
    "    # draw sample\n",
    "    x = np.random.uniform(low = -1, high = 1, size = 1)\n",
    "    y = np.random.uniform(low = -1, high = 1, size = 1)\n",
    "    x_samples.append(x)\n",
    "    y_samples.append(y)\n",
    "\n",
    "    # check if point is within circle\n",
    "    inside = (x**2 + y**2) <= 1\n",
    "    inside_mask.append(inside)\n",
    "\n",
    "    # estimate pi\n",
    "    pi_estimate = 4 * np.sum(inside_mask) / len(x_samples)\n",
    "    running_pi_estimate.append(pi_estimate)\n",
    "\n",
    "    # plot\n",
    "    if i+1 in plot_idxs:\n",
    "        x_arr = np.array(x_samples).flatten()\n",
    "        y_arr = np.array(y_samples).flatten()\n",
    "        mask = np.array(inside_mask).flatten()\n",
    "        plt.figure(figsize = (4,4))\n",
    "        plt.plot(circ_x, circ_y, ls = '--')\n",
    "        plt.scatter(x_arr[mask], y_arr[mask], color = 'tab:red', s = 2)\n",
    "        plt.scatter(x_arr[~mask], y_arr[~mask], color = 'black', s = 2)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.xlim([-1.05, 1.05])\n",
    "        plt.ylim([-1.05, 1.05])  \n",
    "        plt.title(f'Iterations: {i+1} \\n Pi Estimate {pi_estimate}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c6807-b8d6-460a-afb4-b82883b1d92a",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "\n",
    "Let's now track the estimate over time. As $N$ increases, our estimate for $\\pi$ should converge to the true value. Since each sample is an independent test, either in or outside the circle (a.k.a. a Bernoulli trial) with success probability $p = \\pi/4$, the central limit theorem tells us that the standard error on our estimate is:\n",
    "\n",
    "$$ \\sigma_\\pi = 4 \\sqrt{\\frac{p(1-p)}{N}} \\sim \\frac{1}{\\sqrt{N}}$$\n",
    "\n",
    "The $\\frac{1}{\\sqrt{N}}$ scaling is the generic Monte Carlo convergence rate.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6314b-5595-4de3-915d-43c95a60110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty estimates\n",
    "N_arr  = np.arange(1, len(running_pi_estimate) + 1)\n",
    "pi_est = np.array(running_pi_estimate)\n",
    "p      = np.pi / 4\n",
    "envelope = 4 * np.sqrt(p * (1 - p) / N_arr)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(running_pi_estimate, label = r'$\\pi$-estimate')\n",
    "plt.hlines(np.pi, 0, len(running_pi_estimate), ls = '--', color = 'black', label = r'True $\\pi$ value')\n",
    "plt.legend()\n",
    "plt.xlim(0, len(running_pi_estimate))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$\\pi$ estimate')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(running_pi_estimate, label = r'$\\pi$-estimate')\n",
    "plt.fill_between(N_arr-1, pi_est - envelope, pi_est + envelope,\n",
    "                 alpha = 0.2, color = 'steelblue', label = r'$1\\sigma$ ($\\sim 1/\\sqrt{N}$)')\n",
    "\n",
    "plt.hlines(np.pi, 0, len(running_pi_estimate), ls = '--', color = 'black', label = r'True $\\pi$ value')\n",
    "plt.legend()\n",
    "plt.xlim(1, len(running_pi_estimate))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$\\pi$ estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2c558-fcdc-4aa9-9490-c50ed37b396b",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "## Geometry to Integrals\n",
    "\n",
    "What we just did is **Monte Carlo integration**. The area of the circle is:\n",
    "\n",
    "$$A_\\text{circle} = \\int_{-1}^{1}\\int_{-1}^{1} \\mathbb{1}[x^2 + y^2 \\leq 1] \\, dx \\, dy$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ \\mathbb{1}[x^2 + y^2 \\leq 1] = \\begin{cases} 1 & \\text{if } x^2 + y^2 \\leq 1 \\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "Rather than analytically calculating the area of a circle, in this case we could have calculated the integral using a grid search. This is fine in two-dimensions, but not practicle in higher dimensions. Instead, we approximated it by sampling:\n",
    "\n",
    "$$A_\\text{circle} \\approx \\frac{A_\\text{square}}{N} \\sum_{i=1}^{N} \\mathbb{1}[x_i^2 + y_i^2 \\leq 1]$$\n",
    "\n",
    "This is just a fancy way of saying we did random sampling. But the point is that this generalises. For *any* integral $I = \\int f(\\mathbf{x}) \\, d\\mathbf{x}$ over some domain, we can estimate it by drawing uniform samples $\\mathbf{x}_i$ and computing the average of $f(\\mathbf{x}_i)$ scaled by the volume of the domain:\n",
    "\n",
    "\n",
    "$$I \\approx \\frac{V}{N} \\sum_{i=1}^{N} f(\\mathbf{x}_i)$$\n",
    "\n",
    "Importantly, the convergence rate $\\sim 1/\\sqrt{N}$ is independent of dimensionality. Grid based numerical integration scales as $N^d$ (The curse of dimensionality). Monte Carlo does not. \n",
    "\n",
    "## The Efficiency Catch\n",
    "\n",
    "In 2D, about $\\pi/4 \\approx 78.5\\%$ of our samples land inside the circle, most of our random throws are \"useful\". This is rarely the case in higher dimensions. \n",
    "\n",
    "Consider the analogous problem: a $d$-dimensional unit hypersphere inscribed in a $d$-dimensional hypercube with side length 2. The volume of a hypercube is:\n",
    "\n",
    "$$ V_\\text{hypercube} = s^d $$\n",
    "\n",
    "The volume of a hypersphere is:\n",
    "\n",
    "$$ V_\\text{hypersphere} = \\frac{\\pi^{d/2}}{\\Gamma(\\frac{d}{2}+1)} r^d$$\n",
    "\n",
    "Here, $\\Gamma$ is [Euler's Gamma function](https://en.wikipedia.org/wiki/Gamma_function). Let's plot the number of useful samples over time (i.e. the samples within the hypersphere)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3513c51-c17a-40c0-892f-35d5e6719d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "d = np.arange(1, 26)\n",
    "\n",
    "# Calcalate volumes\n",
    "hypercube_volume = 2**d\n",
    "hypersphere_volume = ((np.pi**(d/2)) / (gamma(d/2 + 1))) * 1**d\n",
    "frac = hypersphere_volume / hypercube_volume\n",
    "\n",
    "\n",
    "plt.figure(figsize = (6,5))\n",
    "plt.plot(d, frac, '-o')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Volume ratio')\n",
    "plt.yscale('log')\n",
    "\n",
    "print(f\"d=2:  {frac[1]:.4f}  (1 in ~{1/frac[1]:.1f} samples useful)\")\n",
    "print(f\"d=5:  {frac[4]:.4f}  (1 in ~{1/frac[4]:.0f} samples useful)\")\n",
    "print(f\"d=10: {frac[9]:.2e}  (1 in ~{1/frac[9]:.0f} samples useful)\")\n",
    "print(f\"d=20: {frac[19]:.2e}  (1 in ~{1/frac[19]:.0f} samples useful)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59903a1f-9bbb-403c-8e29-3d3c9edb1dfe",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "As dimensionality increases, the sphere occupies a vanishing fraction of the cube. Almost every random sample lands outside the sphere. They are not \"wasted\" (they still contribute to the estimate), but the signal-to-noise ratio becomes catastrophic. This is the fundamental problem with naive Monte Carlo in high dimensions. The interesting region, whether its a geometeric shape, or the high probability region of a posterior distribution becomes incredibly small. \n",
    "\n",
    "This is the problem MCMC solves. Instead of throwing darts uniformly and hoping they land somewhere useful, MCMC constructs a random walk that preferentially visits the interesting region. The samples are no longer independent (they form a correlated chain), and they're no longer uniform (they're drawn from the target distribution$^1$). But they're efficient. Every sample is, in some sense, useful.\n",
    "\n",
    "*$^1$ We will come back to the importance of these points shortly.*\n",
    "\n",
    "---------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58582304-55fa-49d0-8637-447f454fcee5",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h1>Markov Chains</h1>\n",
    "\n",
    "We have the \"Monte Carlo\" part. But naive Monte Carlo (throwing darts uniformly) fails in high dimensions because the interesting region is a vanishingly small fraction of the total volume. We need a smarter way to generate random samples, one that concentrates its effort where it matters. This is where Markov Chains come in (the second MC in MCMC).\n",
    "\n",
    "<h2>A Simple Example: Observing at the AAT</h2>\n",
    "\n",
    "Those of you who have observed at the Anglo-Australian Telescope at Siding Spring will know that roughly a third of nights are lost to weather (rain, fog, lightning, clouds, etc). But anyone who has actually been on a run knows that bad weather is *not* randomly sprinkled across the schedule. Bad nights come in streaks. If tonight is closed, tomorrow is more likely to be closed too. The same front that shut you down doesn't vanish overnight. Conversely, a clear night is a good omen for the next one.\n",
    "\n",
    "The overall 33% loss rate is an average over all nights. But the night-to-night weather is **correlated**. \n",
    "\n",
    "Let's model AAT weather as a two-state Markov chain: Open and Closed. The weather tomorrow depends only on the weather tonight:\n",
    "\n",
    "- If tonight is open, there's a 80% chance tomorrow is open and a 20% chance tomorrow is closed.\n",
    "- If tonight is closed, there's a 40% chance tomorrow is open and a 60% chance tomorrow is closed.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/MarkovChain.PNG\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "We can write this as a transition matrix:\n",
    "\n",
    "$$T = \\begin{pmatrix} 0.80 & 0.20 \\\\ 0.40 & 0.60 \\end{pmatrix}$$\n",
    "\n",
    "where $T_{ij}$ is the probability of going from state $i$ to state $j$. This is a Markov chain: the weather tomorrow depends *only* on the weather tonight, not on the entire history of the run. This is called the memoryless property. You might see this written as such:\n",
    "\n",
    "$$P(\\theta_{n+1} \\mid \\theta_n, \\theta_{n-1}, \\ldots, \\theta_0) = P(\\theta_{n+1} \\mid \\theta_n)$$\n",
    "\n",
    "This just says that the probability of the next state being conditional on all previous states is the same as the probability of the next state being conditional on only the prior state. \n",
    "\n",
    "Note: in reality, weather isn't perfectly Markov but it's a decent approximation, and it captures the essential point: the overall rate (33% closed) emerges from correlated night-to-night transitions, not from independent coin flips.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe58360-5437-469c-b9eb-8c829a0f8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix: rows = current state, columns = next state\n",
    "# State 0 = Open, State 1 = Closed\n",
    "T = np.array([[0.80, 0.20],\n",
    "              [0.40, 0.60]])\n",
    "\n",
    "# Simulate an observing season\n",
    "np.random.seed(42)\n",
    "n_nights = 365\n",
    "weather = np.zeros(n_nights, dtype=int)\n",
    "weather[0] = 0  # first night is open\n",
    "\n",
    "for i in range(1, n_nights):\n",
    "    weather[i] = np.random.choice([0, 1], p=T[weather[i-1]])\n",
    "\n",
    "# Running fraction of open nights\n",
    "open_fraction = np.cumsum(weather == 0) / np.arange(1, n_nights + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f2e19-e12a-4d72-8b97-5ca08c3a52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot schedule\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "colors = ['tab:blue' if w == 0 else 'tab:orange' for w in weather[:365]]\n",
    "axes[0].bar(range(365), np.ones(365), color=colors, width=1.0, edgecolor='none')\n",
    "axes[0].set_xlim(0, 365)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_xlabel('Night')\n",
    "axes[0].set_title('green = open, orange = closed ‚Äî note the streaks')\n",
    "\n",
    "# Bottom convergence of open fraction\n",
    "axes[1].plot(open_fraction, color='black', lw=1.5)\n",
    "axes[1].axhline(2/3, ls='--', color='black', label=f'Stationary: 2/3 ‚âà 0.667')\n",
    "axes[1].set_xlabel('Night')\n",
    "axes[1].set_ylabel('Fraction of open nights')\n",
    "axes[1].set_title('Running fraction of open nights')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(0, n_nights)\n",
    "axes[1].set_ylim(0.4, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c73db-9643-4d01-b8c3-99ec179a6f63",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h2>The Stationary Distribution</h2>\n",
    "\n",
    "Look at the top panel. The weather comes in streaks, runs of open nights followed by runs of closures. On any given night, the weather is correlated with the night before. Yet, the bottom panel shows that the running fraction of open nights converges to a stable value, regardless of whether the season started clear or cloudy.\n",
    "\n",
    "This stable value is the **stationary distribution** $\\boldsymbol{\\pi}^*$. It satisfies:\n",
    "\n",
    "$$\\boldsymbol{\\pi}^* = \\boldsymbol{\\pi}^* T$$\n",
    "\n",
    "In words: if the chain is currently distributed according to $\\boldsymbol{\\pi}^*$, then after one transition it's *still* distributed according to $\\boldsymbol{\\pi}^*$. The distribution is self-perpetuating. So the chain predicts a 33% closure rate, matching the AAT weather statistics.\n",
    "\n",
    "Let's verify that the chain converges to this regardless of starting conditions:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ab9e9-31fe-46ff-8bc3-7d364fb9abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "n_nights = 3*365\n",
    "\n",
    "for start_state, color, label in [(0, 'tab:blue', 'Start open'), (1, 'tab:orange', 'Start closed')]:\n",
    "    for trial in range(50):\n",
    "        weather = np.zeros(n_nights, dtype=int)\n",
    "        weather[0] = start_state\n",
    "        for i in range(1, n_nights):\n",
    "            weather[i] = np.random.choice([0, 1], p=T[weather[i-1]])\n",
    "        open_frac = np.cumsum(weather == 0) / np.arange(1, n_nights + 1)\n",
    "        ax.plot(open_frac, color=color, alpha=0.3, lw=1)\n",
    "\n",
    "    ax.plot([], [], color=color, label=label, lw=2)\n",
    "\n",
    "ax.axhline(2/3, ls='--', color='black', label='Stationary: 2/3', lw=2)\n",
    "ax.set_xlabel('Night')\n",
    "ax.set_ylabel('Fraction of open nights')\n",
    "ax.set_title('Convergence to stationary distribution ‚Äî regardless of starting conditions')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, n_nights)\n",
    "ax.set_ylim(0.3, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ea77d-831e-4d63-b3df-7fd5525ad51d",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h2>Extending to Continuous Distributions</h2>\n",
    "\n",
    "The AAT weather chain had two states. But most quantities we care about in astronomy are continuous: seeing, flux, temperature, redshift, metaliccity. Can a Markov chain produce a continuous stationary distribution?\n",
    "\n",
    "Let's stay at the AAT, but instead of tracking whether the dome is open or closed, track the seeing (FWHM in arcseconds) hour by hour through an observing season. The seeing at AAT has a few key properties:\n",
    "- The median is around 1.5\"\n",
    "- It's positively skewed ‚Äî you occasionally get terrible 3‚Äì4\" conditions, but rarely get sub-arcsecond seeing\n",
    "- It's correlated hour to hour ‚Äî a period of good seeing is more likely to be followed by another hour of good seeing than a random draw from the overall distribution (similar atmospheric conditions persist)\n",
    "\n",
    "We can model this as a Markov chain in exactly the same spirit as the weather example. Instead of a transition matrix, we have a transition rule: this hour's seeing depends on the previous hour's seeing, plus some noise, with a tendency to drift back toward the site's typical value. This is an autoregressive process (AR(1)) ‚Äî \"autoregressive\" just means \"the next value depends on the previous value,\" which is exactly the Markov property. The \"(1)\" means it only looks back one step.\n",
    "\n",
    "The transition rule is:\n",
    "\n",
    "$$s_{n+1} = \\mu + \\alpha\\,(s_n - \\mu) + \\varepsilon, \\qquad \\varepsilon \\sim \\mathcal{N}(0,\\, \\sigma^2)$$\n",
    "\n",
    "where:\n",
    "- $s_n$ is the (log-)seeing at hour $n$\n",
    "- $\\mu$ is the long-run average log-seeing for the site (i.e. what the seeing \"wants\" to be)\n",
    "- $\\alpha$ is the **persistence** parameter ($0 \\leq \\alpha < 1$). High $\\alpha$ means the seeing this hour strongly resembles last hour; $\\alpha = 0$ means no memory at all\n",
    "- $\\varepsilon$ is a random perturbation, sampled from a normal distribution\n",
    "- $\\sigma$ controls the size of that fluctuation\n",
    "\n",
    "Read it as: \"next hour's seeing = the site average, plus a fraction $\\alpha$ of however far the current seeing is from that average, plus random noise.\" The $\\alpha(s_n - \\mu)$ term is mean reversion: if the seeing is currently worse than average, it tends to drift back, but not all at once.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eb77e-76d0-43c4-b147-bcfc7975f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_seeing(mu_log, alpha, sigma, n_hours, start=None):\n",
    "    \"\"\"Simulate a Markov chain of seeing values (FWHM) via AR(1) in log-space.\"\"\"\n",
    "    log_seeing = np.zeros(n_hours)\n",
    "    log_seeing[0] = start if start is not None else mu_log\n",
    "    \n",
    "    for i in range(1, n_hours):\n",
    "        log_seeing[i] = mu_log + alpha * (log_seeing[i-1] - mu_log) + np.random.normal(0, sigma)\n",
    "    \n",
    "    return np.exp(log_seeing)  # convert back to arcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a70617-54a4-4628-a66e-202e7bd3b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT: median ~1.5\", skewed, moderate persistence\n",
    "aat_seeing = simulate_seeing(mu_log=np.log(1.5), alpha=0.8, sigma=0.25, n_hours=5000, start=np.log(3.0))\n",
    "\n",
    "# Mauna Kea: median ~0.6\", tighter, similar persistence  \n",
    "mk_seeing = simulate_seeing(mu_log=np.log(0.6), alpha=0.8, sigma=0.18, n_hours=5000, start=np.log(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62221ad9-eebd-4ddf-a89b-0802507b24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# --- Top row: AAT ---\n",
    "axes[0, 0].plot(aat_seeing[:500], lw=0.8, color='tab:blue')\n",
    "axes[0, 0].set_ylabel('Seeing (arcsec)')\n",
    "axes[0, 0].set_xlabel('Hour')\n",
    "axes[0, 0].set_title('AAT ‚Äî hourly seeing (first 500 hours)')\n",
    "axes[0, 0].axhline(1.5, ls='--', color='black', alpha=0.5, label='Median (1.5\")')\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "\n",
    "axes[0, 1].hist(aat_seeing[200:], bins=80, density=True, alpha=0.7, color='tab:blue', label='Chain histogram')\n",
    "axes[0, 1].axvline(np.median(aat_seeing[200:]), ls='--', color='black', label=f'Median: {np.median(aat_seeing[200:]):.2f}\"')\n",
    "axes[0, 1].set_xlabel('Seeing (arcsec)')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('AAT ‚Äî stationary distribution')\n",
    "axes[0, 1].set_xlim(0, 5)\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "\n",
    "# --- Bottom row: Mauna Kea ---\n",
    "axes[1, 0].plot(mk_seeing[:500], lw=0.8, color='tab:orange')\n",
    "axes[1, 0].set_ylabel('Seeing (arcsec)')\n",
    "axes[1, 0].set_xlabel('Hour')\n",
    "axes[1, 0].set_title('Mauna Kea ‚Äî hourly seeing (first 500 hours)')\n",
    "axes[1, 0].axhline(0.6, ls='--', color='black', alpha=0.5, label='Median (0.6\")')\n",
    "axes[1, 0].legend(fontsize=9)\n",
    "\n",
    "axes[1, 1].hist(mk_seeing[200:], bins=80, density=True, alpha=0.7, color='tab:orange', label='Chain histogram')\n",
    "axes[1, 1].axvline(np.median(mk_seeing[200:]), ls='--', color='black', label=f'Median: {np.median(mk_seeing[200:]):.2f}\"')\n",
    "axes[1, 1].set_xlabel('Seeing (arcsec)')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Mauna Kea ‚Äî stationary distribution')\n",
    "axes[1, 1].set_xlim(0, 3)\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74d1e4-40fb-4543-95dd-7c9745432a8d",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "The left panels show the trace: the sequence of seeing values hour after hour. Notice the streaks: runs of good seeing and runs of bad seeing, just like the open/closed weather streaks. Each hour's seeing depends on the previous hour. The samples are correlated.\n",
    "\n",
    "The right panels show the histograms of those chains, i.e. the stationary distributions. Both are continuous, skewed, and positive. They look like real seeing distributions because the same underlying physics (persistent atmospheric conditions with random perturbations) is what produces the Markov property in real weather.\n",
    "\n",
    "The AAT chain settles into a distribution peaked around 1.5\" with a heavy tail toward 4\". The Mauna Kea chain settles around 0.6\" with a tighter spread. The takeaway is that the shape of the stationary distribution is entirely determined by the transition rules.\n",
    "\n",
    "Now, notice what we didn't do: we never wrote down the stationary distribution analytically. We never said \"the seeing follows a log-normal with these parameters.\" We defined a transition rule (how this hour relates to the previous hour), ran the chain, and the stationary distribution emerged.\n",
    "\n",
    "MCMC does this in reverse. We start$^2$ with a target distribution (the posterior $P(\\theta|D)$) and we create transition rules such that the chain's stationary distribution is exactly that target. The chain then produces samples from the posterior, and the histogram of those samples converges to the posterior shape.\n",
    "\n",
    "So, how do we engineer those transition rules?\n",
    "\n",
    "*$^2$This does not mean that we need to already know the posterior.*\n",
    "\n",
    "-----------\n",
    "\n",
    "\n",
    "# üèõÔ∏è Historical Aside 2: Monte Carlo and the Nuclear Bomb\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Pioneerclub.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "         Foreground: Fremont Street, Las Vegas. Background: The (stemless) mushroom cloud of a nuclear bomb test, likely the priscilla test during operation plumbob. Las Vegas branded itself as the \"Up and Atom City\". Hotels, including the Pioneer Club, held \"Atomic Cocktails\" parties, and tourists watched the explosions from hotel balconies or downtown rooftops.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "After Stanislaw Ulam came up with Monte Carlo sampling for answering the question about the proportion of solvable solitaire games, he described his idea to John von Neumann. Von Neumann immediately realised its significance for solving a major unsolved problem at Los Alamos: neutron diffusion within fissile material.\n",
    "\n",
    "The core problem was this. In a nuclear weapon, a neutron enters the bomb core and one of several things happens: it gets absorbed by a nucleus and triggers fission (releasing more neutrons), it gets absorbed without fission, it scatters off a nucleus and changes direction and energy, or it escapes the material entirely. Whether the bomb works (whether you get a sustained chain reaction) depends on the balance of these outcomes averaged over enormous numbers of neutrons, each taking a random walk through the material. Each neutron's path is a stochastic trajectory through 3D space with random scattering angles, random energy losses, and probabilistic absorption. The probability of each event depends on the neutron's energy, the local material composition, and the density, which itself is changing because the material is imploding.\n",
    "\n",
    "Classically, the physicists would need to solve the [Boltzmann transport equation](https://en.wikipedia.org/wiki/Boltzmann_equation), which governs neutron behaviour in a bomb core. But solving this was analytically intractable for realistic bomb geometries. Yet the physicists did have the necessary nuclear data: mean free paths, scattering cross-sections, energy transfer distributions, etc. What Ulam and von Neumann realised is that you don't need to solve the integral. You can just simulate individual neutrons: pick a starting position and direction, draw random numbers to decide what happens at each step, follow the neutron until it either escapes or gets absorbed, and repeat for thousands of neutrons. The bulk quantities of interest (the neutron multiplication factor, the energy deposition profile, whether a given geometry achieves criticality) emerge as averages over many simulated histories. This is Monte Carlo: each neutron plays a random game, and you estimate the physics by playing the game many times and counting outcomes. \n",
    "\n",
    "In 1947, von Neumann wrote a letter containing an 81-step pseudocode which was essentially the first Monte Carlo algorithm designed for electronic computation. He proposed tracking 100 neutrons through 100 collisions each and estimated that it would take 5 hours on ENIAC. In 1948, the first simulations were complete. Crucially, the Monte Carlo approach meant you could change the bomb geometry (make the plutonium pit thicker, add a uranium tamper, change the explosive lens configuration) and rerun the simulation to see how it affected the chain reaction. Before Monte Carlo, these design decisions relied on crude analytical approximations and physical intuition. After Monte Carlo, you could iterate computationally. This is a large part of why the hydrogen bomb program progressed as fast as it did in the early 1950s.\n",
    "\n",
    "In 1949 in Los Angeles, a symposium on Monte Carlo methods was held. The attendees included von Neumann, Tukey, and Neyman among others. This conference was the first time many of the techniques were formally published, and it led to the adoption of Monte Carlo methods by the wider community.\n",
    "\n",
    "### John von Neumann\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/poker.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "         Stanislaw Ulam claiming his winnings in a game of poker; Nick Metropolis visible on lower-right edge of photo. Metropolis once described what a triumph it was to win ten dollars from John von Neumann, author of a famous treatise on game theory. He then bought his book for five dollars and pasted the other five inside the cover as a symbol of victory\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "<hr style=\"border: none; border-top: 1px solid #ccc; margin: 20px 100px;\">\n",
    "<p style=\"text-align: center; font-style: italic; margin: 10px 60px;\">\n",
    "\"I am thinking about something much more important than bombs; I am thinking about computers.\"\n",
    "<br><span style=\"font-style: normal; font-size: 0.9em;\">‚Äî von Neumann, in a letter to a colleague during WW2</span>\n",
    "</p>\n",
    "<hr style=\"border: none; border-top: 1px solid #ccc; margin: 20px 100px;\">\n",
    "\n",
    "\n",
    "John was born in Budapest, Hungary, in 1903. He was a true prodigy and was able to memorise and recite very lengthy documents. By 17, while still in high school, he had co-published a paper on Cantor's set theory. After being discouraged from pursuing pure mathematics by his father, he came to a compromise: John would complete a degree in chemical engineering at ETH Zurich while simultaneously completing a PhD in mathematics at the University of Budapest. At age 22 he earned his PhD. He was extremely prolific, writing many papers while still in Europe. In 1930, he started working at Princeton as faculty while younger than 30. Allegedly, he was often mistaken for a graduate student. He would often host parties and was known for flowing cocktails (he drank a lot). Perhaps related, he was also known to be a terrible driver, having at least once crashed his car into a tree. Apparently, an intersection near Princeton was informally named \"von Neumann corner\" as he frequently crashed there.\n",
    "\n",
    "He was not the only Hungarian who worked at Los Alamos. In fact there were a surprising number not only from Hungary, but from his high school specifically. Around the time of the Manhattan Project and the following years was the first time that \"flying saucers\" (or UFOs, or UAPs) were culturally significant. This led to conversations around Los Alamos about them, including one that involved Enrico Fermi coining the Fermi Paradox (\"If the universe is so apparently habitable, where are all the aliens?\"). An often joked solution was that they were already here and they called themselves Hungarians. This was due to the large number of freakishly smart Hungarians around, including von Neumann, and the (now outdated) belief that the Hungarian language was isolated from any other language.\n",
    "\n",
    "In 1943, Oppenheimer invited von Neumann to Los Alamos. He was an expert in the non-linear physics of hydrodynamics and shock waves. His principal contribution to the project was to the implosion nuclear bomb (\"Fat Man\" style) rather than to the gun-type bomb (\"Little Boy\" style). The implosion type bomb is what ended up being more effective, and is the design of modern nuclear weapons. A problem that was becoming apparent during the Manhattan Project was that gun-type bombs, in which a conventional explosive shoots a bullet piece into a target piece to compress it into supercriticality, did not work for the man-made plutonium they had. The implosion style bomb, in which a spherical piece of plutonium is surrounded by precisely timed explosions in order to compress it into criticality, was being worked on, but many doubted it would work. Von Neumann was a major supporter of the implosion design and worked on it extensively due to his knowledge of hydrodynamics and shock waves. His invention of the explosive lens design was what led to the bomb's success.\n",
    "\n",
    "On a darker note, von Neumann also sat on the target selection committee. His knowledge of shock wave reflections led to a calculation that optimised explosion height for maximised destruction. An airburst at the right height produces a Mach stem (a reinforced shockwave from the interaction of incident and reflected waves) that dramatically increases destructive potential, but also reduces fallout. He also supported nuking Kyoto, reasoning that the destruction of the cultural capital would be psychologically devastating. This was overruled, and Hiroshima and Nagasaki were selected instead. After WW2, von Neumann consulted for many military agencies in the US. He was also a strong advocate for \"preventative\" war, in which the USA would attack the Soviets before they obtained nuclear weapons. He was quoted saying \"If you say bomb them tomorrow, I say why not today?\". He did, however, support Oppenheimer when his patriotism was under attack, and allegedly warned Edward Teller that his colleagues at the Livermore lab were too reactionary.\n",
    "\n",
    "In 1955, like many of his colleagues, he was diagnosed with cancer, possibly due to witnessing many nuclear explosions. As the cancer spread to his brain, his mental faculties deteriorated and he was moved to a private room after his screams and shouts disturbed other patients. His phones were monitored, as military officials worried that he might accidentally leak nuclear secrets in his delirium. There is no moral to this story.\n",
    "\n",
    "-----------------\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25d39a-ff92-4b2b-913d-9e4e8fba3bb8",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/MANIAC2.jpg\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "         Mrs. Lois Cook-Leurgan a computer programmer examines the main arithmetic unit of the MANIAC (Mathematical Analyzer, Numerical Integrator And Computer). The computer played an important part in thermonuclear calculations at the University of California's Los Alamos Scientific Laboratory in New Mexico. This was the first computer that the Metropolis Algorithm was run on.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "<h1>Part 3: The Metropolis Algorithm</h1>\n",
    "\n",
    "To answer the question of how to create transition rules that lead to a stationary distribution which matches the posterior, we can use the Metropolis algorithm.\n",
    "\n",
    "The algorithm that Metropolis, the Rosenbluths, and the Tellers published in 1953 is surprisingly simple:\n",
    "\n",
    "1. Start at some position $\\theta_0$ in parameter space.\n",
    "2. Propose a new position by adding a random nudge: $\\theta' = \\theta_n + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\text{prop}^2)$.\n",
    "3. Compute the acceptance ratio:\n",
    "    $$\\alpha = \\min\\left(1, \\;\\frac{P(\\theta'|D)}{P(\\theta_n|D)}\\right)$$\n",
    "5. Accept or reject: draw $u \\sim \\text{Uniform}(0, 1)$. If $u < \\alpha$, move to $\\theta'$. Otherwise, stay at $\\theta_n$.\n",
    "6. Repeat from step 2.\n",
    "\n",
    "That's it, the entire algorithm is: propose, compare, accept or reject.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9304b7-c116-4cb9-aded-b4880e13e217",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h2>The acceptance ratio</h2>\n",
    "\n",
    "The core of the algorithm is the acceptance ratio:\n",
    "\n",
    "$$\\alpha = \\min\\left(1, \\;\\frac{P(\\theta'|D)}{P(\\theta_n|D)}\\right)$$\n",
    "\n",
    "Let's walk through this term by term:\n",
    "\n",
    "- $P(\\theta_n|D)$ is the posterior density at the current position (where we are now).\n",
    "- $P(\\theta'|D)$ is the posterior density at the proposed position (where we're thinking of moving).\n",
    "- The ratio $P(\\theta'|D) / P(\\theta_n|D)$ compares the two. If the ratio is 2, the proposed point is twice as probable as the current point. If it's 0.1, the proposed point is ten times less probable.\n",
    "- The $\\min(1, \\ldots)$ caps the ratio at 1, because a probability can't exceed 1.\n",
    "\n",
    "Note that since $P(\\theta|D) \\propto \\mathcal{L}(\\theta)\\pi(\\theta)$, this ratio is really comparing the product of likelihood and prior at the two points. A proposed point can be accepted because it fits the data better (higher likelihood), because it is more consistent with our prior knowledge (higher prior), or both. The Bayesian comparison is baked into every single step of the chain.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c90291-e2d0-47fd-844d-86767c7dea08",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h2>The three outcomes</h2>\n",
    "\n",
    "There are three possible outcomes at each step:\n",
    "\n",
    "1. The proposed point has higher posterior density ($P(\\theta'|D) > P(\\theta_n|D)$):\n",
    "\n",
    "The ratio $P(\\theta'|D)/P(\\theta_n|D)$ is greater than 1, so $\\alpha = \\min(1, \\text{something} > 1) = 1$. We always accept. The chain moves to the new point. This makes sense: if the proposed position is more probable, we should go there.\n",
    "\n",
    "2. The proposed point has equal posterior density ($P(\\theta'|D) = P(\\theta_n|D)$):\n",
    "\n",
    "The ratio is exactly 1, so $\\alpha = 1$. We always accept. The chain moves. This also makes sense: there's no reason to prefer one point over another if they're equally probable.\n",
    "\n",
    "3. The proposed point has lower posterior density ($P(\\theta'|D) < P(\\theta_n|D)$):\n",
    "\n",
    "The ratio is between 0 and 1, and we accept with exactly that probability. Concretely: if the proposed point is half as probable as the current point, the ratio is 0.5 and we accept with 50% probability. If it's a hundred times less probable, the ratio is 0.01 and we accept with 1% probability. We draw a uniform random number $u$ between 0 and 1, and accept if $u < \\alpha$. Otherwise, we stay put and record the current position again.\n",
    "\n",
    "This third case is the important one. The chain can move to lower-probability regions, but it does so reluctantly and in proportion to how much worse they are. This is what allows the chain to explore the full shape of the posterior, including its tails and secondary peaks, rather than getting stuck at the single highest point. If we only ever accepted uphill moves (cases 1 and 2), the algorithm would just be an optimiser that finds the MAP. By occasionally accepting downhill moves, it becomes a sampler that maps out the entire distribution.\n",
    "\n",
    "Below is a visualisation of the three outcomes:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1d926-21a2-46f4-9856-78575b20bb3f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "x = np.linspace(-5, 6, 1000)\n",
    "\n",
    "def density(xv):\n",
    "    return 0.4 * np.exp(-0.5*((xv-2)/0.8)**2) + 0.6 * np.exp(-0.5*((xv+1)/1.2)**2)\n",
    "\n",
    "target_vals = density(x)\n",
    "norm = target_vals.max()\n",
    "target_vals /= norm\n",
    "\n",
    "cases = [\n",
    "    {'title': 'Case 1: Uphill ‚Üí always accept',\n",
    "     'tc': -2.8, 'tp': -1.0,\n",
    "     'result': 'Accept ‚úì', 'rcol': 'tab:green'},\n",
    "    {'title': 'Case 2: Equal density ‚Üí always accept', \n",
    "     'tc': -2.5, 'tp': 2.71,\n",
    "     'result': 'Accept ‚úì', 'rcol': 'tab:green'},\n",
    "    {'title': 'Case 3: Downhill ‚Üí accept with prob. Œ±',\n",
    "     'tc': 2.0, 'tp': 4.0,\n",
    "     'result': 'Maybe...', 'rcol': 'tab:orange'},\n",
    "]\n",
    "\n",
    "for ax, c in zip(axes, cases):\n",
    "    tc, tp = c['tc'], c['tp']\n",
    "    pc = density(tc) / norm\n",
    "    pp = density(tp) / norm\n",
    "    \n",
    "    # Background\n",
    "    ax.plot(x, target_vals, 'k-', lw=2.2)\n",
    "    ax.fill_between(x, target_vals, alpha=0.06, color='grey')\n",
    "    \n",
    "    # Vertical reference lines\n",
    "    ax.vlines(tc, 0, pc, color='tab:blue', ls=':', alpha=0.3, lw=1)\n",
    "    ax.vlines(tp, 0, pp, color=c['rcol'], ls=':', alpha=0.3, lw=1)\n",
    "    \n",
    "    # Points (BELOW arrow)\n",
    "    ax.plot(tc, pc, 'o', color='tab:blue', ms=14, zorder=5, \n",
    "            markeredgecolor='white', markeredgewidth=2)\n",
    "    ax.plot(tp, pp, 's', color=c['rcol'], ms=13, zorder=5, \n",
    "            markeredgecolor='white', markeredgewidth=2)\n",
    "    \n",
    "    # Curved arrow (ON TOP of points)\n",
    "    rad = -0.4 if tp > tc else 0.4\n",
    "    ax.annotate('', \n",
    "                xy=(tp, pp + 0.03), \n",
    "                xytext=(tc, pc + 0.03),\n",
    "                arrowprops=dict(arrowstyle='->', color='#333', lw=2,\n",
    "                               connectionstyle=f'arc3,rad={rad}'),\n",
    "                zorder=10)\n",
    "    \n",
    "    # Labels (ABOVE arrow)\n",
    "    label_bbox = dict(boxstyle='round,pad=0.15', facecolor='white', \n",
    "                      edgecolor='none', alpha=0.9)\n",
    "    \n",
    "    ax.text(tc, pc + 0.09, r'$\\theta_n$', ha='center', fontsize=14, \n",
    "            color='tab:blue', fontweight='bold', zorder=15, bbox=label_bbox)\n",
    "    \n",
    "    if pp < 0.1:\n",
    "        ax.text(tp + 0.35, pp + 0.02, r\"$\\theta'$\", ha='left', fontsize=14,\n",
    "                color=c['rcol'], fontweight='bold', zorder=15, bbox=label_bbox)\n",
    "    else:\n",
    "        ax.text(tp, pp + 0.09, r\"$\\theta'$\", ha='center', fontsize=14, \n",
    "                color=c['rcol'], fontweight='bold', zorder=15, bbox=label_bbox)\n",
    "    \n",
    "    # Result badge\n",
    "    ax.text(0.5, 0.94, c['result'], transform=ax.transAxes, ha='center', \n",
    "            fontsize=13, fontweight='bold', color=c['rcol'],\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', \n",
    "                      edgecolor=c['rcol'], alpha=0.95, lw=1.5))\n",
    "    \n",
    "    # Alpha value\n",
    "    ratio = pp / pc\n",
    "    ratio_text = r'$\\alpha$ = 1' if ratio >= 1.0 else rf'$\\alpha$ = {ratio:.2f}'\n",
    "    ax.text(0.5, 0.83, ratio_text, transform=ax.transAxes, ha='center', \n",
    "            fontsize=11, color='#666')\n",
    "    \n",
    "    ax.set_title(c['title'], fontsize=11, fontweight='bold', pad=14)\n",
    "    ax.set_xlabel(r'$\\theta$', fontsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(-5, 5.5)\n",
    "    ax.set_ylim(-0.02, 1.4)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axes[0].set_ylabel(r'$P(\\theta|D)$', fontsize=12)\n",
    "plt.tight_layout(w_pad=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97672f-b422-41a9-b64a-2a129e0fcee7",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "<h2>Example: Fitting a Radial Velocity Curve</h2>\n",
    "We will use a manual implementation of the metropolis algorithm to fit a single planet on a circular orbit to a some radial velocity data from the star.\n",
    "\n",
    "### Model\n",
    "$$ v_r(t) = \\gamma + K \\sin \\left(\\frac{2\\pi t}{P} + \\phi \\right) $$\n",
    "\n",
    "We will set the true value and (simple) priors:\n",
    "\n",
    "| Parameter | Symbol | True Value | Prior | Notes |\n",
    "|-----------|:------:|------------|-------|-------|\n",
    "| System velocity | $\\gamma$ | 5 m/s | Uniform(-50, 50) | |\n",
    "| Semi-amplitude  | K | 2 m/s | Uniform(0, 100) | Must be positive |\n",
    "| Period | P | 30 days | Uniform(0.1, 200) | |\n",
    "| Phase | $\\phi$ | 0.5 rad | Uniform(0, $2\\pi$) | |\n",
    "\n",
    "For the data, we will generate 15 observations, randomly sampled over a 100 day period to mimic a real observing campaign. We will include uncertainties of $\\sim1 m/s$, which is typical of a good, but not leading, spectrograph. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86575cca-4260-4ad0-b65b-a224c17e0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Get observations\n",
    "n_obs = 15\n",
    "t_obs = np.sort(np.random.uniform(0, 100, n_obs))\n",
    "\n",
    "# STD of Uncertainties, ~1m/s with some spread (differing SNR on different nights)\n",
    "v_err = np.random.uniform(0.8, 2.5, n_obs)\n",
    "\n",
    "# True Parameters\n",
    "gamma_true = 5   # m/s\n",
    "K_true     = 2  # m/s\n",
    "P_true     = 30  # days\n",
    "phi_true   = 0.5 # rads\n",
    "\n",
    "# Generate data\n",
    "v_model = gamma_true + K_true * np.sin(2*np.pi*t_obs/P_true + phi_true)\n",
    "v_obs   = v_model + v_err * np.random.randn(n_obs) # realisation of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd861a4-8ea3-4ee9-a0a8-0d5c8cd152a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth model curves\n",
    "t_fine = np.linspace(0, 100, 500)\n",
    "v_fine = gamma_true + K_true * np.sin(2 * np.pi * t_fine / P_true + phi_true)\n",
    "\n",
    "phase_fine = np.linspace(0, 1, 500)\n",
    "v_phase_fine = gamma_true + K_true * np.sin(2 * np.pi * phase_fine + phi_true)\n",
    "\n",
    "# Phase-fold the observations\n",
    "phase_obs = ((t_obs / P_true) % 1)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4),\n",
    "                         gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "# Panel 1: Time series\n",
    "ax = axes[0]\n",
    "ax.errorbar(t_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "            ecolor='grey', capsize=2, ms=5, label='Observations')\n",
    "ax.plot(t_fine, v_fine, color='tab:blue', lw=1.5, alpha=0.7, label='True model')\n",
    "ax.axhline(gamma_true, color='grey', ls=':', lw=0.8)\n",
    "ax.set_xlabel('Time [days]')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_title('RV Time Series')\n",
    "\n",
    "# Panel 2: Phase-folded\n",
    "ax = axes[1]\n",
    "ax.errorbar(phase_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "            ecolor='grey', capsize=2, ms=5)\n",
    "ax.plot(phase_fine, v_phase_fine, color='tab:blue', lw=1.5, alpha=0.7)\n",
    "ax.axhline(gamma_true, color='grey', ls=':', lw=0.8)\n",
    "ax.set_xlabel('Phase')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.set_title('Phase-folded')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa918fc7-4ed0-4dc6-82c1-6367e4e643b3",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "We will now write a few functions showing the manual implementation of the Metropolis algorithm. Take your time to read it, so you can verify it follows the steps listed above. We will write 4 functions: `log_likelihood`, `log_prior`, `log_posterior`, and the main implentation `metropolis`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed45b7-e2d6-4140-a9e0-f52ab2f7f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, t, v_obs, v_err):\n",
    "    '''\n",
    "    Gaussian log-likelihood for RV data\n",
    "    ===================================\n",
    "    Inputs:\n",
    "        - theta: array of parameters [gamma, K, P, phi]\n",
    "        - t    : array of observation times\n",
    "        - v_obs: array of observed RVs\n",
    "        - v_err: array of measurement uncertainties\n",
    "    Output:\n",
    "        log-likelihood value\n",
    "    '''\n",
    "    # extract parameters\n",
    "    gamma, K, P, phi = theta\n",
    "    model = gamma + K*np.sin(2*np.pi*t/P +phi)\n",
    "\n",
    "    # calculate log-like (proportional to chi2)\n",
    "    log_like = -0.5*np.sum(((v_obs-model)/v_err)**2)\n",
    "    return log_like\n",
    "\n",
    "def log_prior(theta):\n",
    "    '''\n",
    "    Apply priors on all parameters\n",
    "    '''\n",
    "    # extract parameter\n",
    "    gamma, K, P, phi = theta\n",
    "    \n",
    "    # Uniform prior: log-probability is 0 (constant) inside bounds, -inf outside.\n",
    "    # For non-uniform priors, you'd return the log of the probability density instead.\n",
    "    if not (-50 < gamma < 50):\n",
    "        return -np.inf\n",
    "    if not (0 < K < 100):\n",
    "        return -np.inf\n",
    "    if not (1 < P < 200):\n",
    "        return -np.inf\n",
    "    if not (0 < phi < 2 * np.pi):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def log_posterior(theta, t, v_obs, v_err):\n",
    "    '''\n",
    "    Unnormalised log-post = log_prior + log_likelihood\n",
    "    '''\n",
    "    lp = log_prior(theta)\n",
    "\n",
    "    # check if within prior bounds\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp+log_likelihood(theta, t, v_obs, v_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d08caa-2b7e-4ae3-81dd-229856c12b71",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "Recall that the algorithm is:\n",
    "1. Start at some position $\\theta_0$ in parameter space.\n",
    "2. Propose a new position by adding a random nudge: $\\theta' = \\theta_n + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\text{prop}^2)$.\n",
    "3. Compute the acceptance ratio:\n",
    "    $$\\alpha = \\min\\left(1, \\;\\frac{P(\\theta'|D)}{P(\\theta_n|D)}\\right)$$\n",
    "5. Accept or reject: draw $u \\sim \\text{Uniform}(0, 1)$. If $u < \\alpha$, move to $\\theta'$. Otherwise, stay at $\\theta_n$.\n",
    "6. Repeat from step 2.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625235b9-a7f1-4990-baac-35c73a2fa422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(log_post, theta0, proposal_sigma, n_steps, args=()):\n",
    "    '''\n",
    "    Metropolis sampler with Gaussian proposals\n",
    "    ==========================================\n",
    "    Inputs:\n",
    "        - log_post       : function\n",
    "        - theta0         : initial parameters\n",
    "        - proposal_sigma : array, std of Gaussian proposal per dimension\n",
    "        - n_steps        : number of iterations\n",
    "        - args           : tuple of arguments to pass to log_post\n",
    "    Outputs:\n",
    "        - chain           : array of shape (n_steps + 1, n_dim)\n",
    "        - acceptance_rate : float\n",
    "    '''\n",
    "    n_dim = len(theta0)\n",
    "    chain = np.zeros((n_steps + 1, n_dim))\n",
    "    chain[0] = theta0\n",
    "    \n",
    "    log_p_current = log_post(theta0, *args)\n",
    "    n_accepted = 0\n",
    "\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        # propose new point\n",
    "        theta_prop = chain[i] + proposal_sigma * np.random.randn(n_dim)\n",
    "        \n",
    "        # calculate probability at proposed point\n",
    "        log_p_prop = log_post(theta_prop, *args)\n",
    "        \n",
    "        # acceptance ratio\n",
    "        log_alpha = log_p_prop - log_p_current\n",
    "\n",
    "        if np.log(np.random.uniform()) < log_alpha:\n",
    "            # accept: move to proposed point\n",
    "            chain[i+1] = theta_prop\n",
    "            log_p_current = log_p_prop\n",
    "            n_accepted += 1\n",
    "        else:\n",
    "            # reject: REPEAT the current position\n",
    "            chain[i+1] = chain[i]\n",
    "\n",
    "    acceptance_rate = n_accepted / n_steps\n",
    "    return chain, acceptance_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3fc133-a29d-4ca4-a1e0-f4c529bff378",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify; padding: 20px; background-color: rgba(0, 64, 133, 0.08); border: 2px solid rgba(0, 64, 133, 0.4); border-radius: 10px;\">\n",
    "\n",
    "<h3>Exercise: Map the Code to the Algorithm</h3>\n",
    "\n",
    "For each step of the Metropolis algorithm, identify which line(s) of the implementation above correspond to it. Try to answer before revealing.\n",
    "\n",
    "<b>Step 1:</b> Start at some position $\\theta_0$\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "<code>chain.append(theta0)</code> and <code>log_p_current = log_post(theta0, *args)</code>\n",
    "\n",
    "We store the starting point and evaluate the posterior there so we have something to compare against.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<b>Step 2:</b> Propose a new position $\\theta' = \\theta_n + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\text{prop}^2)$\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "<code>theta_prop = chain[-1] + proposal_sigma * np.random.randn(n_dim)</code>\n",
    "\n",
    "<code>chain[-1]</code> is $\\theta_n$, and <code>proposal_sigma * np.random.randn(n_dim)</code> is $\\varepsilon$.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<b>Step 3:</b> Compute the acceptance ratio $\\alpha = \\min\\left(1, \\; P(\\theta'|D) / P(\\theta_n|D)\\right)$\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "<code>log_p_prop = log_post(theta_prop, *args)</code><br>\n",
    "<code>log_alpha = log_p_prop - log_p_current</code>\n",
    "\n",
    "We work in log-space, so the ratio $P(\\theta'|D) / P(\\theta_n|D)$ becomes a subtraction: $\\log\\alpha = \\log P(\\theta'|D) - \\log P(\\theta_n|D)$. The $\\min(1, \\cdot)$ is handled implicitly by the accept/reject step.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<b>Step 4:</b> Accept or reject: draw $u \\sim \\text{Uniform}(0, 1)$. If $u < \\alpha$, move to $\\theta'$. Otherwise, stay at $\\theta_n$.\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "<code>if np.log(np.random.uniform()) < log_alpha:</code><br>\n",
    "&emsp;&emsp;<code>chain.append(theta_prop)</code><br>\n",
    "&emsp;&emsp;<code>log_p_current = log_p_prop</code>\n",
    "\n",
    "Instead of comparing $u < \\alpha$, we compare $\\log u < \\log \\alpha$. This avoids exponentiating the log-posterior back to real space, which can overflow. Note that if the proposal is rejected, we don't append anything ‚Äî the chain just doesn't grow, and <code>chain[-1]</code> remains the current position for the next iteration.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<b>Step 5:</b> Repeat from step 2.\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "<code>while len(chain) < n_steps:</code>\n",
    "\n",
    "The loop continues until we have collected <code>n_steps</code> accepted samples.\n",
    "\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64139d-30ea-42f5-a794-ac0ee1273aab",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "Let's now run the sampler using our data generated above\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051b796-7fe1-4ac7-876a-1c04bd511677",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Starting point (deliberately offset from truth)\n",
    "theta0 = np.array([0, 15, 20, 1.0])\n",
    "\n",
    "# Proposal widths. these matter a lot, and we'll show why\n",
    "proposal_sigma = np.array([1.0, 1.0, 4.0, 0.3])\n",
    "\n",
    "# Run\n",
    "n_steps = 50000\n",
    "chain, acc_rate = metropolis(\n",
    "    log_posterior, theta0, proposal_sigma, n_steps,\n",
    "    args=(t_obs, v_obs, v_err)\n",
    ")\n",
    "print(f\"Acceptance rate: {acc_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f41d7-6d5a-4fe0-87f2-bd4661667788",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(chain[:,0], lw = 0.5, label = 'Chain')\n",
    "plt.ylabel(r'System Velocity $\\gamma$')\n",
    "plt.xticks([])\n",
    "plt.xlim(0, n_steps)\n",
    "plt.hlines(gamma_true, 0, n_steps, ls ='--', color = 'black', label = 'True Value', alpha = 0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(chain[:,1], lw = 0.5, label = 'Chain')\n",
    "plt.ylabel('Semi Amplitude K')\n",
    "plt.xticks([])\n",
    "plt.xlim(0, n_steps)\n",
    "plt.hlines(K_true, 0, n_steps, ls ='--', color = 'black', label = 'True Value', alpha = 0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(chain[:,2], lw = 0.5, label = 'Chain')\n",
    "plt.hlines(P_true, 0, n_steps, ls ='--', color = 'black', label = 'True Value', alpha = 0.5)\n",
    "plt.ylabel('Period P')\n",
    "plt.xticks([])\n",
    "plt.xlim(0, n_steps)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(chain[:,3], lw = 0.5, label = 'Chain')\n",
    "plt.hlines(phi_true, 0, n_steps, ls ='--', color = 'black', label = 'True Value', alpha = 0.5)\n",
    "plt.ylabel(r'Phase $\\phi$')\n",
    "plt.xlim(0, n_steps)\n",
    "plt.xticks([])\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.xlim(0, n_steps)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a46dc0-7bfd-41e1-8ebd-e79e4f3edfac",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify; padding: 20px; background-color: rgba(0, 64, 133, 0.08); border: 2px solid rgba(0, 64, 133, 0.4); border-radius: 10px;\">\n",
    "\n",
    "<b>Question 1:</b> Can you identify the burn in?\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "\n",
    "The burn-in in this case is very short, only around 10 steps. You can see it as the rapid change in values at the start of the chains.\n",
    "</div>\n",
    "</details>\n",
    "\n",
    "<b>Question 2:</b> What is happening in the Period chain?\n",
    "\n",
    "<details style=\"margin: 10px 0;\">\n",
    "<summary style=\"cursor: pointer; font-weight: bold; padding: 10px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">Click to reveal</summary>\n",
    "\n",
    "<div style=\"margin-top: 10px; padding: 15px; background-color: rgba(0, 64, 133, 0.12); border: 1px solid rgba(0, 64, 133, 0.4); border-radius: 5px;\">\n",
    "    Notice that it is jumping from ~30 to ~20 and ~60. These are close to integer ratios. Essentially you are seeing aliasing.\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398119c-ca05-40ae-8368-ab125cbd6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r'$\\gamma$', r'$K$', r'$P$', r'$\\phi$']\n",
    "truths = [gamma_true, K_true, P_true, phi_true]\n",
    "\n",
    "fig = corner.corner(chain, labels=labels, truths=truths, \n",
    "                    truth_color='black', show_titles=True,\n",
    "                    title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b8c1f-26f8-4c10-93f9-65b886bdef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth model curves\n",
    "t_fine = np.linspace(0, 100, 500)\n",
    "v_fine = gamma_true + K_true * np.sin(2 * np.pi * t_fine / P_true + phi_true)\n",
    "phase_fine = np.linspace(0, 1, 500)\n",
    "v_phase_fine = gamma_true + K_true * np.sin(2 * np.pi * phase_fine + phi_true)\n",
    "# Phase-fold the observations\n",
    "phase_obs = ((t_obs / P_true) % 1)\n",
    "\n",
    "# MLE: the sample with the highest log-posterior\n",
    "log_posts = np.array([log_posterior(chain[i], t_obs, v_obs, v_err) for i in range(len(chain))])\n",
    "mle = chain[np.argmax(log_posts)]\n",
    "v_mle = mle[0] + mle[1] * np.sin(2 * np.pi * t_fine / mle[2] + mle[3])\n",
    "v_mle_phase = mle[0] + mle[1] * np.sin(2 * np.pi * phase_fine + mle[3])\n",
    "\n",
    "# 100 random posterior samples\n",
    "idx = np.random.choice(len(chain), 100, replace=False)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4),\n",
    "                         gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "# Panel 1: Time series\n",
    "ax = axes[0]\n",
    "for i in idx:\n",
    "    g, K, P, phi = chain[i]\n",
    "    ax.plot(t_fine, g + K * np.sin(2 * np.pi * t_fine / P + phi),\n",
    "            color='black', lw=0.3, alpha=0.15)\n",
    "ax.plot([], [], color='black', lw=1, alpha=0.5, label='Posterior samples')  # dummy for legend\n",
    "ax.plot(t_fine, v_mle, color='tab:red', lw=2, ls='--', label='MAP estimate')\n",
    "ax.errorbar(t_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "            ecolor='grey', capsize=2, ms=5, label='Observations', zorder=5)\n",
    "ax.plot(t_fine, v_fine, color='tab:blue', lw=1.5, alpha=0.7, label='True model')\n",
    "ax.axhline(gamma_true, color='grey', ls=':', lw=0.8)\n",
    "ax.set_xlabel('Time [days]')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_title('RV Time Series')\n",
    "\n",
    "# Panel 2: Phase-folded\n",
    "ax = axes[1]\n",
    "for i in idx:\n",
    "    g, K, P, phi = chain[i]\n",
    "    ax.plot(phase_fine, g + K * np.sin(2 * np.pi * phase_fine + phi),\n",
    "            color='tab:orange', lw=0.3, alpha=0.15)\n",
    "ax.plot(phase_fine, v_mle_phase, color='tab:red', lw=2, ls='--')\n",
    "ax.errorbar(phase_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "            ecolor='grey', capsize=2, ms=5, zorder=5)\n",
    "ax.plot(phase_fine, v_phase_fine, color='tab:blue', lw=1.5, alpha=0.7)\n",
    "ax.axhline(gamma_true, color='grey', ls=':', lw=0.8)\n",
    "ax.set_xlabel('Phase')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.set_title('Phase-folded')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b034c9-28b4-48b1-ba51-c851d31d20a2",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify; padding: 20px; background-color: rgba(0, 64, 133, 0.08); border: 2px solid rgba(0, 64, 133, 0.4); border-radius: 10px;\">\n",
    "\n",
    "<h3>Exercise: How does more data change the posterior?</h3>\n",
    "\n",
    "With 15 observations over 100 days, we saw that the posterior had a somewhat significant width, and the period showed aliasing at integer ratios of the true period. Let us know see what happens as we collect more data.\n",
    "\n",
    "**Task:** Regenerate the observe data `n_obs = 25` and then `n_obs = 100`, keeping everthing else the same. For each case:\n",
    "\n",
    "1) Run the Metropolis sampler\n",
    "2) Plot the trace plots\n",
    "3) Make a corner plot\n",
    "4) Plot the posterior samples over the data (as above)\n",
    "\n",
    "**Ask yourself the following:**\n",
    "- How does the width of each marginal posterior change?\n",
    "- Does the period aliasing dissapear? Why?\n",
    "- Does the MAP (Maximum A Posteriori) get closer to the truth?\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907eb5c-ca77-4fe4-a1df-47e53ce50cd6",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "The proposal standard deviation $\\sigma_\\text{prop}$ is one of the most important tuning parameters in the Metropolis algorithm. We initally used $\\sigma_\\text{prop} = [1.0, 1.0, 4.0, 0.3]$ above, and you should have gotten an acceptance rate of $3.2%$. It is low, but not awfully so. \n",
    "\n",
    "If your proposals are too small (i.e $\\sigma_\\text{prop}$ are small), then each proposed step is only a small pertubation from the current position. This small perturbation will likely land at a very similar posterior density, so the acceptance ratio will be close to 1, meaning the step is almost always accepted. This might sound good, but it means the chain is taking baby steps, and isn't exploring the posterior effectively as it basically just hanging around the same spot. \n",
    "\n",
    "If $\\sigma_\\text{prop}$ is large, each proposed step jumps far from the current position. In a typical posterior, most of the parameter space has negligible propability, so a large random jump almost certainly lands somewhere terrible. This means that the acceptance ratio is tiny, the step is rejected, and the chain stays where it is. \n",
    "\n",
    "You want something in between: large enough to cover ground, but not so large that they overshoot into unimportant spaces.\n",
    "\n",
    "### Case 1: Proposals too small\n",
    "\n",
    "Go back and ensure that the number of observations is reset to 15. Now instead of $\\sigma_\\text{prop} = [1.0, 1.0, 4.0, 0.3]$, lower it to $\\sigma_\\text{prop} = [0.1, 0.1, 0.2, 0.01]$. What you should see, now that the proposal width is small relative to the posterior width, is that almost every proposal lands near the current position and is thus accepted. You should have an acceptance rate of $>50%$. This sounds good, but look at the trace plots. You should see that the period stays around 20 days, rather than 30 days. This is because it is incredibly unlikely that a proposed point will stray far from the current position (of around 20 days). \n",
    "\n",
    "Another way to think of this is that all of the samples are very highly correlated. This means that the effective sample size is far less than the actual number of samples. This is the slow diffusion failure mode. \n",
    "\n",
    "### Case 2: Proposals too large\n",
    "Set $\\sigma_\\text{prop} = [10, 10, 25, 1.5]$ and rerun the above code. As the proposal width is very large, the proposed points almost always land in regions of negligible posterior density and are rejected. You should observe an acceptance rate of $\\sim 0.03%$, and you should notice it takes much longer to execute. While it does explore parameter space, it is wasting a lot of computational cycles: many points are being proposed, evalutated, and rejected for no gain. While this is not ideal, we do get a better posterior than the too small case. Typically, you want an acceptance rate of ~1-25%. \n",
    "\n",
    "## Practical Notes\n",
    "\n",
    "### Initialisation\n",
    "**Where should you start you chain?** Hogg & Foreman-Mackey (2018) recommend initialising near a reasonable estimate. For example, near the maximum likelihood solution, or near a value you expect from your prior knowledge. You can initialise randomly within the prior, but this wastes computational cycles on burn-in. \n",
    "\n",
    "**If you are concerend that your posterior might be multimodal**, initialise multiple chains at different random locations. If they all converge to the same place that is good. If they don't, then you need to take some care. See the discussion on multi-modality in the main tutorial.\n",
    "\n",
    "### Thinning\n",
    "You will sometimes see recommendations to \"thin\" your chain. This means keep only every $k$-th sample, discarding the rest. The only reason why you would do this is for storage purposes. It throws away valid (if correlated) information. \n",
    "\n",
    "### A note on `emcee`\n",
    "In a lot of astronomy papers, you will often see the package `emcee` used (Foreman-Mackey et al. 2013). It is an affine-invarient$^‚Ä†$ ensemble sampler. `emcee` uses an ensemble of walkers that collectively adapt to the posterior geometry, avoiding the need to manually tune a proposal distribution. However, `emcee` is fundamentally a Metropolis-like sampler and does not use gradient information (which we will be using later). This means it struggles in high dimensions (~>10). \n",
    "\n",
    "### Tuning\n",
    "Tuning of the proposal distributions can only be done during burn-in. You cannot tune while collecting final samples, as this would violate the Markov property.\n",
    "\n",
    "-----------------\n",
    "*$^‚Ä†$ don't worry about what this means, we won't be using it in these tutorials. Google it if you are interested*\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5369e6e-e531-4c79-b367-b2298a6f2852",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "## Aside: Metropolis-Hastings\n",
    "Everything we have done so far is the Metropolis algorithm, not Metropolis-Hastings. The difference is small, as the MH algorithm is a generalisation of the Metropolis algorithm. Nevertheless, you will see Metropolis-Hastings talked about everywhere, with little comment on the Metropolis algorithm alone. \n",
    "\n",
    "In the Metropolis algorithm, the proposal distribution is symmetric. The probability of proposing $\\theta'$ from $\\theta$ is the same as the probability of proposing $\\theta$ from $\\theta'$. The Gaussian proposal we used satisfied this. Metropolis-Hastings generalises the algorithm to allow for a non-symmetric proposal distribution. If the proposal distribution is not symmetric, you would be violating the *detailed balance* condition (see the upcoming section). Thus we need to correct for the asymmetry. We do this by modifying the acceptance ratio, so it becomes:\n",
    "\n",
    "$$ \\alpha = \\text{min}\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta)} \\cdot \\frac{q(\\theta | \\theta')}{q(\\theta' | \\theta)} \\right)$$\n",
    "\n",
    "The extra factor of $q(\\theta | \\theta')/q(\\theta' | \\theta)$ is the Hastings correction. In practice, people just use HMC/NUTS, but you can use asymmetric proposals if you like. \n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad189953-13c4-438d-8163-075d3744e0f1",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "# Part 5: The Typical Set\n",
    "\n",
    "We now have a working metropolis sampler, and we have seen how proposal widths affect performance. But before we go onto more modern/advanced algorithms, we need to understand the failure modes of these older algorithms. \n",
    "\n",
    "Consider a D-dimensional Gaussian centred on the origin. Where does most of the probability *mass* live? Naively, one might answer at the origin (near the mode), after all, that is where the density is the highest. The issue with this is that the mode is just one point - it takes up essentially no volume. If you care about where the typical sample is drawn from (which you do, if you are fitting a model to data), you need to also consider probability volume. \n",
    "\n",
    "In D dimensions, the volume of a thin shell, at radius $r$ scales as $r^{d-1}$. So while the density at the origin is maximal at the origin, there is essentially no volume there.  The density (assuming a gaussian), falls off as $e^{-r^2/2}$. The probability mass is the product of these two effects (volume times density) peaks at a radius of $r = \\sqrt{d-1}$. The following figure and caption come from Betancourt 2018:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Betancourt2018.PNG\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "    <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "   In high dimensions a probability density, œÄ(q), will concentrate around its mode, but the volume over which we integrate that density, dq, is much larger away from the mode. Contributions to any expectation are determined by the product of density and volume, œÄ(q) dq, which then concentrates in a nearly-singular neighborhood called the typical set (grey).\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "This is to say, that the region that contributes most to any expectation$^‚Ä°$ is not the mode but at an (increasingly) thin shell around it. This shell is the typical set. Below is a 1D slice of a N-dimensional Gaussian, showing the typical set:\n",
    "\n",
    "*$^‚Ä°$: Every summary statistic that you extract from an MCMC chain (mean, variance, credible intervals, predictable observables) is an expectation.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fbcb8-d7f7-4b77-b603-a4fa69790c1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 4))\n",
    "\n",
    "r = np.linspace(0, 25, 2000)\n",
    "\n",
    "for ax, d in zip(axes, [2, 10, 100, 500]):\n",
    "    mass = chi.pdf(r, d)\n",
    "    \n",
    "    ax.plot(r, mass, 'k', lw=2)\n",
    "    ax.axvline(np.sqrt(d-1), ls='--', color='tab:red', \n",
    "               label=r'$r = \\sqrt{d-1}$' + f' = {np.sqrt(d-1):.1f}')\n",
    "    ax.axvline(0, ls=':', color='tab:blue', alpha=0.5, label='Mode (r = 0)')\n",
    "    ax.fill_between(r, mass, alpha=0.15, color='black')\n",
    "    ax.set_xlabel('Radius r')\n",
    "    ax.set_ylabel('Posterior mass')\n",
    "    ax.set_title(f'd = {d}')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_xlim(0, max(np.sqrt(d) * 2, 5))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bf521-bdd7-4a61-a5c3-5f58bef714a5",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "## Why typical sets matter for MCMC\n",
    "\n",
    "The typical set explains the failure modes we saw with Metropolis:\n",
    "1) When the proposals were too small, the chain explores a tiny neighbourhood and never reaches the typical set.\n",
    "2) When the proposals were too large, almost every jump lands outside the thin typical set shell, and most proposals are rejected.\n",
    "3) Goldilocks issue: in higher dimensions, the typical set becomes increasingly thin. When Metropolis needs to propose a new position, it must choose a very specific set of directions that lie on the typical set. However, the number of directions in higher dimensions grows exponentially, so the probability of randomly guessing a good direction falls dramatically.\n",
    "\n",
    "The below figure (again from Betancourt 2018) demonstrates this issue:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Fig10Bentancourt.PNG\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "    <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "  In high dimensions, the Random Walk Metropolis proposal density (green) is strongly biased towards the outside of the typical set (red) where the target density, and hence the Metropolis acceptance probability vanishes. (a) If the proposal variances are large then the proposals will stray too far away from the typical set and are rejected. (b) Smaller proposal variances stay within the typical set and hence are accepted, but the resulting transition density concentrates tightly around the initial point. Either way we end up with a Markov chain that explores the typical set very, very slowly.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd22c59-4ec2-4ed2-9368-b66fa9f358eb",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "# Part 6: Detailed Balance & Ergodicity\n",
    "\n",
    "Above, we have claimed that MCMCs will prodice samples from the posterior. For this to work, two (or three, depending on how you count) properties need to be fufilled. These are detailed balance, and ergodicity.\n",
    "\n",
    "## Detailed Balance\n",
    "\n",
    "A Markov chain with transition kernel $K(\\theta'|\\theta)$ satisfies detailed balance with respect to $\\pi(\\theta)$ if:\n",
    "$$ \\pi(\\theta)K(\\theta'|\\theta) =  \\pi(\\theta')K(\\theta|\\theta')$$\n",
    "In plain English, the probability of being at $\\theta$ and transitioning to $\\theta'$ equals the probability of the opposite move, going from $\\theta'$  to $\\theta$.\n",
    "\n",
    "If detailed balance holds, then $\\pi$ is a stationary distribution of the chain. As we have the $\\text{min}(1,\\cdot)$ in the algorithm as the acceptance ratio, this corrects for the fact that we are preferrentially exploring regions of higher probability mass, satistfying detailed balance. \n",
    "\n",
    "## Ergodicity\n",
    "Detailed balance guarantees that $\\pi$ is *a* stationary distribution, but not that the chain will find it. For that, we need to satistify the ergodicity condition: the chain must be irreducible (can reach any state) and aperiodic (no determinisitic cycles). \n",
    "\n",
    "For Metropolis with a Gaussian proposal, the Gaussian has support everywhere (i.e. it can propose a point anywhere, there are no points that have probability zero of proposal - this satisfies irreducuiblitlity), and rejection means the chain can stay in place, which allows for aperiodicity.\n",
    "\n",
    "-------------\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27d206-309e-41a8-b1be-deaf1173adeb",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "# Part 7: Hamiltonian Monte Carlo & NUTS\n",
    "> A note on scope / complexity: This section covers materials which would take 1-2 lectures to cover properly. You don't need to understand all of the nuts and bolts, but an understanding of why this works is useful. I would highly recommend reading the Betancourt 2018 paper on this, as this largely follows their derivation quite closely.\n",
    "\n",
    "## Roadmap\n",
    "\n",
    "| Section | Purpose |\n",
    "|---------|---------|\n",
    "| A Vector Field | Introduces the idea of a direction field that follows the typical set |\n",
    "| The Gradient |  Identifies the gradient as a candidate and shows why it's insufficient |\n",
    "| The Physical Analogy | Reframes the problem as orbital mechanics, motivating momentum as the missing ingredient |\n",
    "| Phase Space | Doubles the parameter space to accommodate position and momentum| \n",
    "| The Canonical Distribution | Defines a joint distribution that recovers the posterior when momentum is discarded |\n",
    "| The Hamiltonian | Encodes the geometry of the typical set in a single scalar function (energy) |\n",
    "| Hamilton's Equations | Derives the vector field ‚Äî the trajectories ‚Äî from the Hamiltonian |\n",
    "| The Hamiltonian-Markov Transition | Assembles the three steps (lift, explore, project) into a working sampler |\n",
    "| The Euclidean-Gaussian Kinetic Energy |Practical choices: kinetic energy|\n",
    "\n",
    "The purpose of Hamiltonian Monte Carlo is to be able to follow the typical set in a principled way, as the typical set is the most important region (*the region where it happens*, if you will). \n",
    "\n",
    "Recall the typical set, from mere inches above: in higher dimensions, the posterior mass is concentrated in a thin shell. As dimension increases, the volume outside the shell is much larger than the volume inside the shell. Almost every random proposal lands outside the shell, which will likely be rejected. No matter how you tune the covariance matrix of the proposal distribution, Metropolis(-Hastings) (MH) will explore the typical set extremly slowly. \n",
    "\n",
    "### A Vector Field\n",
    "\n",
    "In order to make large jumps away from the initial point, and into new unexplored regions of the typical set, we need to exploit the geomettry of the typical set. Specifically, we need transitions that can follow the contours of high probability mass, coherently gliding through the typical set.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Gliding.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "</div>\n",
    "\n",
    "What we need is for our walkers to be able to follow a sign-posted path pointing them in the right direction. To put it more precisely, a vector field aligned with the typical set would be very helpful. By construction, this would move us into a new point in the typical set. We need a way to create this vector field from the information contained within the target distribution. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Spiral.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "  We want something that looks like this.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## The Gradient\n",
    "The natural information that we have not exploited yet is the gradient of the target density. The gradient defines a vector field in parameter space that is sensitive to the geometry of the target distribution. This seems promising, but there is a pretty big issue - the gradient points towards the mode of the distribution, and away from the typical set. \n",
    "\n",
    "This is a hurdle. Can you think of any situation of a vector field pointing to a single point, but there is a way to use that vector field to draw paths that don't follow the field?\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Orbit.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "  Perhaps something like this?\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "To utilise the information in the gradient, we need to complement it with additional geometric constraints that twist the gradient direction to align with the typical set. We need to add **momentum**. Fortunately there is a way to do this, rooted in differential geometry.\n",
    "\n",
    "## The Physical Analogy\n",
    "For reasons rooted in the mathematics of differential geometry (which we won't derive here, because I don't understand it), for every probabilistic system there is a mathematically equivalent physical system that we can reason about more easily. Instead of thinking about a mode, a gradient, and a typical set, we can *equivalently* reason about a planet, a gravitational field, and an orbit. I imagine that if you are an astronomer, this could be helpful.\n",
    "\n",
    "If we place a satellite at rest in the gravitational field, it falls and crahses into the surface of the planet, just as a naive gradient-driven trajectory would crash into the mode. \n",
    "\n",
    "But using the physical picture, we can immediately see a solution: we can give the satelitte enough momentum to counteract the gravitational field and maintain a stable orbit. Too little momentum and it will spiral inward, too much and it flies off. But with enough momentum, the gravitational force and the dynamics are conservative.\n",
    "\n",
    "Hence the key to twisting the gradient vector field into a vector field aligned with the typical set is to expand our probabilistic system with the introduction of auxiliary momentum parameters. There is only one correct way to do this, and it leads directly to Hamiltonian Monte Carlo.\n",
    "\n",
    "## Phase Space\n",
    "Conservative dynamics$^‚ô£$ in physical systems require that volumes are preserved. As the system evolves, any compression in position space must be compensated by a corresponding expansion in momentum space, and vice versa. This means that if we change our parameterisation of parameter space (say working in sin of a parameter rather than the parameter directly), we need to be able to change momentum space so that the parameter-momentum space volume is preserved. To mimic this, we introduce auxiliary momentum parameters $p_n$ to complement each dimension of the target parameter space:\n",
    "\n",
    "$$\\theta_n \\rightarrow (\\theta_n, p_n) $$\n",
    "\n",
    "This expands the D-dimensional parameter space into a 2D-dimensional *phase space*. Note we are not adding a single extra dimension, we are doubling the number of dimensions. Each parameter gets a momentum parameter. \n",
    "\n",
    "--------\n",
    "*Note: from here on we will use $q$ rather than $\\theta$ for our parameters, following the convention of Hamiltonian mechanics where $q$ denotes co-ordinates and $p$ denotes momenta. They are the same thing: $q\\equiv\\theta$*\n",
    "\n",
    "*Also note: in the following we will use the notation $\\pi(q) \\equiv \\pi(\\theta)$ to represent a generic probability distribution function. This is not the prior, and it would be better thought of as the posterior distribution function.*\n",
    "\n",
    "*$^‚ô£$: A system has conservative dynamics when its total energy is constant along any trajectory ‚Äî nothing is gained or lost, only exchanged between kinetic and potential forms. Examples include pendulums and orbits. A consequence of energy conservation is that the dynamics preserve volumes in phase space. Liouville's theorem: if you track a cloud of initial conditions forward in time, the cloud may deform in shape but its total volume remains constant. This volume preservation is what guarantees that the dynamics don't systematically concentrate or disperse probability.*\n",
    "\n",
    "----------\n",
    "\n",
    "## The Canonical Distribution\n",
    "Now that we have expanded to phase space, we need to define a *joint-*probability distribution over both position and momentum. We can't just use $\\pi(q)$ as it says nothing about $p$. And we can't pick an arbitrary joint distribution, because we need the momentum to be auxiliary: when we are done exploring, we throw it away and must be left with samples from the posterior $\\pi(q)$.\n",
    "\n",
    "The solution is to construct the joint distribution as a product:\n",
    "\n",
    "$$\\pi(q, p) = \\pi(p|q) \\pi(q) $$\n",
    "This is called the canonical distribution. The first factor, $\\pi(p|q)$ is a conditional distribution over momentum that we get to choose (more on this shortly). The second factor is the target posterior that we have been talking about this whole time. Written this way, it is immediate from the rules of probability that we can marginalise out the momentum to recover the target:\n",
    "\n",
    "$$\\int \\pi(q, p) dp = \\pi(q)\\cdot \\int \\pi(q| p)dp = \\pi(q)  $$\n",
    "\n",
    "This is to say that if we can build a sampler that explores the joint typical set of $\\pi(q, p)$, then simply discarding the $p$ coordinates gives us samples from $\\pi(q)$, the posterior that we care about. It is kind of like multiplying by one or adding zero in a sense. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Canon.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "  By constructing a probability distribution on phase space that marginalizes to the target distribution, we ensure that the typical set on phase space projects to the typical set of the target distribution. In particular, if we can construct trajectories that efficiently explore the joint distribution (red arrow) they will project to trajectories that efficiently explore the target distribution (green arrow)\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "## The Hamiltonian\n",
    "Because the canonical density does not depend on a particular choice of parameterisation, we can write it in terms of an invariant function called the Hamiltonian:\n",
    "\n",
    "$$\\pi(q,p) = e^{-H(q,p)} $$\n",
    "inverting:\n",
    "$$H(q,p)  = -\\log \\pi(q,p)$$\n",
    "\n",
    "Appealing to the physical analogy, the value of the Hamiltonian at any point in phase space is called the energy at that point. \n",
    "\n",
    "Becuase of the decompositionof the joint density, the Hamiltonian itself decomposes into two terms:\n",
    "$$\\begin{aligned}\n",
    "H(q,p) &= -\\log\\pi(p|q) - \\log\\pi(q) \\\\\n",
    "&\\equiv K(p,q) + V(q)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Here:\n",
    "- $V(q)$ is the potential energy and is completly determined by the target distribution (the posterior). This is the negative log-posterior, and it encodes the landscape the sampler must navigate.\n",
    "- $K(p,q) is the kinetic energy, our choice of momentum distribution. This is unconstrained and must be specified by the implementation.\n",
    "\n",
    "## Hamiltonians Equations\n",
    "Because the Hamiltonian captures the geometry of the typical set, we should be able to use it to generate a vector field oriented with the typical set. Indeed, we can use Hamilton's Equations: \n",
    "\n",
    "$$\\begin{aligned} \\frac{dq}{dt} &= +\\frac{\\partial H}{\\partial p} = \\frac{\\partial K}{\\partial p} \\\\ \\frac{dp}{dt} &= -\\frac{\\partial H}{\\partial q} = -\\frac{\\partial K}{\\partial q} - \\frac{\\partial V}{\\partial q} \\end{aligned}$$\n",
    "\n",
    "Note that $\\partial V/\\partial q$ is the gradient of the negative log-posterior which is exactly the gradient information we wanted to exploit. The equations split the gradient force (which points towards the mode/the planet) across two coupled equations. The gradient changes the momentum, not the position (directly) and the momentum changes the position. The position update $dq/dt$ moves you in the direction of the current momentum, not in the direction of the gradient. The gradient only deflects the trajectory. So these equations do twist the gradient into a vector field that follows the typical set rather than falling towards the mode. \n",
    "\n",
    "Following the Hamiltonian vector field for some time $t$ generates trajectories $\\phi_t(q,p)$ that rapidly move through phase space while being constrained by the typical set. Projecting these trajectories back down onto the target parameter space finally yields the efficient exploration of the typical set that we have been searching for.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/PhaseSpace.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "         Every Hamiltonian Markov transition is comprised of a random lift from the target parameter space onto phase space (light red), a deterministic Hamiltonian trajectory through phase space (dark red), and a projection back down to the target parameter space (light red).\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "## The Hamiltonian-Markov Transition\n",
    "\n",
    "In order to utilise these Hamiltonian trajectories to construct an efficient Markov transition, we need three steps:\n",
    "\n",
    "1) Step 1: **Lift**. To lift an initial point in parameter space into one in phase space, we *sample* momentum from the conditional distribution: $$p\\sim\\pi(p|q) $$ If the intial point was in the typical set of the target of the target distribution, sampling the momentum directly from its conditional distribution guarantees that the lifted point falls into the typical set of the joint phase-space distribution.\n",
    "2) Step 2: **Explore**. Once in phase space, we integrate Hamilton's equations for some time: $$(q,p) \\rightarrow \\phi_t(q,p)$$ By construction, these trajectories coherently push the transition away from the initial point while staying confined to the joint typical set.\n",
    "3) Step 3: **Project**. After integrating, we return to the parameter space by discarding the momentum: $$(q,p)\\rightarrow(q) $$\n",
    "\n",
    "Composing these three steps yields a Hamiltonian Markov transition composed of random trajectories that rapidly explore the target distribution. Out in the tails, the momentum sampling and projection steps allow the chan to rapidly fall toward the typical set. Once the chain has reached the typical set, the Hamiltonian trajectories ensure extremely efficient exploration.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"Images/Jumper.png\" style=\"max-width: 70%; border-radius: 4px;\">\n",
    "     <p style=\"font-size: 0.75em; color: #888; font-style: italic; margin-top: 0.5em; text-align: center;\">\n",
    "         (a) Each Hamiltonian Markov transition lifts the initial state onto a random level set of the Hamiltonian, which can then be explored with a Hamiltonian trajectory before projecting back down to the target parameter space. (b) If we consider the projection and random lift steps as a single momentum resampling step, then the Hamiltonian Markov chain alternates between deterministic trajectories along these level sets (dark red) and a random walk across the level sets (light red).\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "## The Euclidean-Gaussian Kinetic Energy\n",
    "The kinetic energy $K$ (i.e. the choice of momentum distribution) is a free parameter. The standard choice is a Gaussian:\n",
    "\n",
    "$$\\pi(p|q) = \\mathcal{N}(p|0, M)$$\n",
    "\n",
    "In plain language: the momentum $p$ is drawn from a multivariate Gaussian distribution centred on zero with a covariance matrix M. Recall that $K = -\\log\\pi(p|q)$, which gives the kinetic energy:\n",
    "\n",
    "$$K(p) = \\frac{1}{2}p^T M^{-1}p + \\text{const.} $$\n",
    "\n",
    "The matrix M is called the mass matrix (in the physical analogy), or the inverse Euclidean metric in the geometric picture. The choice of M effectively rotates and rescales parameter space. As $M^{-1}$ more closely resembles the covariance of the target distribution, the posterior becomes more isotropic in the transformed space, making the energy levels more uniform and hence easier to explore. If you are familiar with General Relativity, this may sound familiar. M is essentially the metric tensor on parameter space. \n",
    "\n",
    "The optimal choice of $M^{-1} = \\text{Cov}_\\pi (\\theta)$, which is the posterior covariance itself. This is a bit of a chicken and the egg situation, but in practice this gets repeatedly estimated during warmup.\n",
    "\n",
    "As one might expect, it is often hard to analytical solve Hamiltons equations. Instead numerical integrators, such as leapfrog, are used. See the Betancourt 2018 paper for details. \n",
    "\n",
    "### NUTS: The No-U-Turn Sampler\n",
    "\n",
    "HMC has two tuning parameters beyond the mass matrix: the step size $\\varepsilon$ and the number of leapfrog steps $L$ (equivalently, the total integration time $T = L\\varepsilon$).\n",
    "\n",
    "The step size $\\varepsilon$ is adapted automatically during warmup by targeting a specific acceptance probability (typically 0.8). But $L$ is harder to set. Too few steps and you don't move far from the start, you get the same slow diffusion as Metropolis. Too many steps and the trajectory curves back toward the start, wasting computation. The No-U-Turn Sampler (NUTS; Hoffman & Gelman 2014) eliminates $L$ as a tuning parameter entirely. It grows the trajectory in both directions (forward and backward in time) until it detects a U-turn. It then samples a point from the completed trajectory. \n",
    "\n",
    "## Summary\n",
    "\n",
    "To recap the full picture: at each iteration, HMC draws a random momentum (setting a random direction and speed), then simulates a physical trajectory through parameter space using Hamilton's equations, and finally proposes the endpoint as the next sample. The trajectory is computed numerically via the leapfrog integrator, and a Metropolis correction ensures exactness despite integration error. The mass matrix $M$ rescales the posterior geometry so the sampler moves efficiently in all directions, and NUTS automates the trajectory length by stopping when a U-turn is detected. The result is a sampler that makes large, directed moves through the typical set (in contrast to the small, random, diffusive steps of Metropolis) while maintaining the detailed balance and ergodicity guarantees that make it a valid MCMC algorithm.\n",
    "\n",
    "It is basically the G.O.A.T. of MCMC algorithms.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49616f44-b5ac-437f-8b24-87e49d26dee1",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "# Part 8: NumPyro Demonstration\n",
    "\n",
    "In Parts 4‚Äì7 we built MCMC from scratch and developed the theory behind HMC. In practice, you will never implement HMC yourself. You will use a probabilistic programming library that does it all for you. We will use `NumPyro`. \n",
    "\n",
    "NumPyro is a lightweight probabilistic programming library built on top of `JAX`. `JAX` provides automatic differentiation (needed for the gradient $\\partial V/ \\partial q$) and just-in-time compilation. \n",
    "\n",
    "Before we begin, let's check that everything is installed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125c5a1-c4ff-417a-ac09-00b077ee6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_ok = True\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    print(f\"  ‚úì JAX {jax.version}\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó JAX not installed. Run: pip install jax jaxlib\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import jax.numpy as jnp\n",
    "    print(f\"  ‚úì jax.numpy\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó jax.numpy not available\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import numpyro\n",
    "    print(f\"  ‚úì NumPyro {numpyro.version}\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó NumPyro not installed. Run: pip install numpyro\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import numpyro.distributions as dist\n",
    "    from numpyro.infer import MCMC, NUTS, Predictive\n",
    "    from numpyro.diagnostics import print_summary\n",
    "    from jax import random\n",
    "    print(f\"  ‚úì numpyro.infer, numpyro.distributions, numpyro.diagnostics\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó NumPyro submodules not available\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import arviz as az\n",
    "    print(f\"  ‚úì ArviZ\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó ArviZ not installed. Run: pip install arviz\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import corner\n",
    "    print(f\"  ‚úì corner\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó corner not installed. Run: pip install corner\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(f\"  ‚úì matplotlib\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó matplotlib not installed. Run: pip install matplotlib\")\n",
    "    install_ok = False\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"  ‚úì numpy {np.version}\")\n",
    "except ImportError:\n",
    "    print(\"  ‚úó numpy not installed\")\n",
    "    install_ok = False\n",
    "if install_ok:\n",
    "    numpyro.set_platform(\"cpu\")\n",
    "    print(\"\\n  All packages found. You're good to go.\")\n",
    "else:\n",
    "    print(\"\\n  ‚ö†Ô∏è Some packages are missing. Install them before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8ff0b-7d2a-4d72-b72d-90554bca1e05",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "## How NumPyro Models Work\n",
    "\n",
    "A NumPyro model is just a Python function. Inside that function, you use three key primitives:\n",
    "\n",
    "- **`numpyro.sample(\"name\", distribution)`** ‚Äî declares a random variable with a prior distribution. This tells NumPyro: \"this parameter exists, and before seeing data, I believe it follows this distribution.\"\n",
    "\n",
    "- **`numpyro.sample(\"name\", distribution, obs=data)`** ‚Äî declares an observed random variable. This is the likelihood: it says \"the data was generated from this distribution, given the current parameter values.\" The `obs=data` keyword is what distinguishes a prior from a likelihood in NumPyro.\n",
    "\n",
    "- **`numpyro.factor(\"name\", log_value)`** ‚Äî adds an arbitrary log-density contribution to the model's log-probability, without declaring a new random variable. This is useful for custom likelihoods that don't correspond to a built-in distribution. You can think of `numpyro.sample(\"obs\", dist, obs=data)` as syntactic sugar that internally calls `numpyro.factor` with the log-probability of `data` under `dist`.\n",
    "\n",
    "That's it. From these three primitives, NumPyro automatically constructs the log-posterior $\\log[\\mathcal{L}(\\theta)\\pi(\\theta)]$, computes its gradient via JAX autodiff, and runs NUTS.\n",
    "\n",
    "## A Minimal Example\n",
    "\n",
    "Let's fit a coin. We observe 7 heads out of 10 flips and want to infer the bias $\\theta$:\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93927af6-7793-42be-bb77-a63dbdd238e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_model(data):\n",
    "    # Prior: theta is uniform on [0, 1]\n",
    "    theta = numpyro.sample(\"theta\", dist.Uniform(0, 1))\n",
    "    # Likelihood: each flip is Bernoulli with probability theta\n",
    "    numpyro.sample(\"obs\", dist.Bernoulli(theta), obs=data)\n",
    "\n",
    "# Data: 7 heads (1) and 3 tails (0)\n",
    "data = jnp.array([1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
    "\n",
    "# Set up NUTS and run\n",
    "kernel = NUTS(coin_model)\n",
    "mcmc = MCMC(kernel, num_warmup=500, num_samples=2000, num_chains=4)\n",
    "mcmc.run(random.PRNGKey(0), data)\n",
    "mcmc.print_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d2535-f0ee-403b-8e82-c7ed74f00659",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "Let's unpack the inference lines:\n",
    "\n",
    "- `NUTS(coin_model)` ‚Äî wraps your model in the NUTS sampler. This is where all of Part 7 lives: the leapfrog integrator, the mass matrix, the U-turn detection.\n",
    "- `MCMC(kernel, num_warmup=500, num_samples=2000, num_chains=4)` ‚Äî sets up the MCMC run. `num_warmup` is the number of steps used for adaptation (step size, mass matrix) ‚Äî these samples are discarded. `num_samples` is the number of samples to keep per chain. num_chains runs 4 independent chains for diagnostic purposes.\n",
    "- `random.PRNGKey(0)` ‚Äî JAX requires explicit random seeds. This ensures reproducibility.\n",
    "- `mcmc.print_summary()` ‚Äî prints posterior summaries and diagnostics.\n",
    "\n",
    "The columns to pay attention to:\n",
    "\n",
    "- n_eff: effective sample size. You have 8000 total samples (2000 √ó 4 chains), but autocorrelation reduces this. Here n_eff ‚âà 2500, which is plenty.\n",
    "- r_hat: the Gelman-Rubin diagnostic. Should be ~1.00. Values > 1.01 indicate the chains disagree, and you should not trust the results.\n",
    "- Number of divergences (printed separately): should be 0.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893a55d-e6f6-494d-9ba9-5cb84f83af80",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "\n",
    "## Fitting the RV Curve with `NumPyro`\n",
    "\n",
    "*NOTE: This will require some tuning to get it aligned with the posterior from above. Good luck!*\n",
    "\n",
    "\n",
    "Now let's refit the radial velocity curve from Part 4, when we used Metropolis, but now using HMC/NUTS.\n",
    "\n",
    "### Model\n",
    "$$ v_r(t) = \\gamma + K \\sin \\left(\\frac{2\\pi t}{P} + \\phi \\right) $$\n",
    "\n",
    "We will set the true value and (simple) priors:\n",
    "\n",
    "| Parameter | Symbol | True Value | Prior | Notes |\n",
    "|-----------|:------:|------------|-------|-------|\n",
    "| System velocity | $\\gamma$ | 5 m/s | Uniform(-50, 50) | |\n",
    "| Semi-amplitude  | K | 2 m/s | Uniform(0, 100) | Must be positive |\n",
    "| Period | P | 30 days | Uniform(0.1, 200) | |\n",
    "| Phase | $\\phi$ | 0.5 rad | Uniform(0, $2\\pi$) | |\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1d3c8-4ae6-44f1-b8e6-9ca538d5dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv_model(t, v_obs, v_err):\n",
    "    \"\"\"\n",
    "    NumPyro model for a single-planet circular RV orbit.Parameters (all inferred):\n",
    "    gamma : systemic velocity [m/s]\n",
    "    K     : semi-amplitude [m/s]\n",
    "    P     : orbital period [days]\n",
    "    phi   : phase offset [rad]\n",
    "    \"\"\"\n",
    "    gamma = numpyro.sample(\"gamma\", dist.Uniform(-50, 50))\n",
    "    K     = numpyro.sample(\"K\",     dist.Uniform(0, 100))\n",
    "    P     = numpyro.sample(\"P\",     dist.Uniform(1, 200))\n",
    "    phi   = numpyro.sample(\"phi\",   dist.Uniform(0, 2 * jnp.pi))\n",
    "    \n",
    "    # Forward model\n",
    "    model = gamma + K * jnp.sin(2 * jnp.pi * t / P + phi)\n",
    "    \n",
    "    # Likelihood: observed velocities are Gaussian-distributed around the model\n",
    "    numpyro.sample(\"obs\", dist.Normal(model, v_err), obs=v_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15858f1-8ea7-4f12-9f13-5df12069dd5b",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "\n",
    "Note the structure: four `numpyro.sample` calls declare the priors, then one `numpyro.sample(..., obs=...)` call declares the likelihood. The forward model in between is just numpy/jax ‚Äî NumPyro doesn't care what you do between the prior declarations and the likelihood, as long as it's differentiable (which basic arithmetic and trig functions are).\n",
    "\n",
    "Now run it:\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422ea8b-d58a-435a-bd82-6f375e55b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Get observations\n",
    "n_obs = 15\n",
    "t_obs = np.sort(np.random.uniform(0, 100, n_obs))\n",
    "\n",
    "# STD of Uncertainties, ~1m/s with some spread (differing SNR on different nights)\n",
    "v_err = np.random.uniform(0.8, 2.5, n_obs)\n",
    "\n",
    "# True Parameters\n",
    "gamma_true = 5   # m/s\n",
    "K_true     = 2  # m/s\n",
    "P_true     = 30  # days\n",
    "phi_true   = 0.5 # rads\n",
    "\n",
    "# Generate data\n",
    "v_model = gamma_true + K_true * np.sin(2*np.pi*t_obs/P_true + phi_true)\n",
    "v_obs   = v_model + v_err * np.random.randn(n_obs) # realisation of noise\n",
    "\n",
    "# Run NUTS (t_obs, v_obs, v_err are defined from Part 4)\n",
    "kernel = NUTS(rv_model)\n",
    "mcmc = MCMC(kernel, num_warmup=500, num_samples=2000, num_chains=8)\n",
    "mcmc.run(random.PRNGKey(161), jnp.array(t_obs), jnp.array(v_obs), jnp.array(v_err))\n",
    "\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eeaa21-0b3a-44d2-878c-4bf09d521f8e",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "    \n",
    "The arguments after the random key are passed directly to your model function. NumPyro matches them positionally: `t` gets `t_obs`, `v_obs` gets `v_obs`, `v_err` gets `v_err`.\n",
    "    \n",
    "### Extracting and Plotting Samples\n",
    "`mcmc.get_samples()` returns a dictionary mapping parameter names to arrays of posterior samples (concatenated across chains):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c91b52-5e32-41df-986a-d52f7c481b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = mcmc.get_samples()\n",
    "# samples is a dict: {'gamma': array, 'K': array, 'P': array, 'phi': array}\n",
    "# Each array has shape (num_samples * num_chains,) = (8000,)\n",
    "\n",
    "print(f\"Posterior mean of K: {np.mean(samples['K']):.2f} m/s\")\n",
    "print(f\"Posterior std of K:  {np.std(samples['K']):.2f} m/s\")\n",
    "\n",
    "# Corner plot\n",
    "sample_array = np.column_stack([\n",
    "    np.array(samples['gamma']),\n",
    "    np.array(samples['K']),\n",
    "    np.array(samples['P']),\n",
    "    np.array(samples['phi']),\n",
    "])\n",
    "\n",
    "labels = [r'$\\gamma$ [m/s]', r'$K$ [m/s]', r'$P$ [days]', r'$\\phi$ [rad]']\n",
    "truths = [gamma_true, K_true, P_true, phi_true]\n",
    "\n",
    "fig = corner.corner(sample_array, labels=labels, truths=truths,\n",
    "                    truth_color='black', show_titles=True,\n",
    "                    title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3882a3-f237-4c91-858f-aeed6058bf73",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "    \n",
    "Compare the corner plot to the one you made with Metropolis in Part 4. You should see a similar posterior, but the NUTS samples will be much less correlated and the effective sample size should be dramatically higher for the same number of total samples. If you are getting a different posterior, try changing some of the priors, or even reparameterising in freqeuncy rather than using period.\n",
    "\n",
    "### Posterior Predictive Plot\n",
    "Finally, let's draw random posterior samples and plot the corresponding model curves over the data. This is a posterior predictive check: if the model is correct and the inference worked, the posterior curves should bracket the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ad295-9898-4eff-bfe2-7adcf6ab7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fine = np.linspace(0, 100, 500)\n",
    "\n",
    "#Draw 100 random posterior samples\n",
    "idx = np.random.choice(len(sample_array), 100, replace=False)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4),\n",
    "gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "#Panel 1: Time series\n",
    "ax = axes[0]\n",
    "for i in idx:\n",
    "    g, K, P, phi = sample_array[i]\n",
    "    ax.plot(t_fine, g + K * np.sin(2 * np.pi * t_fine / P + phi),\n",
    "    color='black', lw=0.3, alpha=0.15)\n",
    "    \n",
    "ax.plot([], [], color='black', lw=1, alpha=0.5, label='Posterior samples')\n",
    "ax.plot(t_fine, gamma_true + K_true * np.sin(2 * np.pi * t_fine / P_true + phi_true),\n",
    "color='tab:blue', lw=1.5, alpha=0.7, label='True model')\n",
    "ax.errorbar(t_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "ecolor='grey', capsize=2, ms=5, label='Observations', zorder=5)\n",
    "ax.set_xlabel('Time [days]')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_title('Posterior Predictive: Time Series')\n",
    "\n",
    "#Panel 2: Phase-folded\n",
    "ax = axes[1]\n",
    "phase_fine = np.linspace(0, 1, 500)\n",
    "phase_obs = ((t_obs / P_true) % 1)\n",
    "for i in idx:\n",
    "    g, K, P, phi = sample_array[i]\n",
    "    ax.plot(phase_fine, g + K * np.sin(2 * np.pi * phase_fine + phi),\n",
    "    color='tab:orange', lw=0.3, alpha=0.15)\n",
    "    \n",
    "ax.plot(phase_fine,\n",
    "gamma_true + K_true * np.sin(2 * np.pi * phase_fine + phi_true),\n",
    "color='tab:blue', lw=1.5, alpha=0.7)\n",
    "ax.errorbar(phase_obs, v_obs, yerr=v_err, fmt='o', color='k',\n",
    "ecolor='grey', capsize=2, ms=5, zorder=5)\n",
    "ax.set_xlabel('Phase')\n",
    "ax.set_ylabel('Radial velocity [m/s]')\n",
    "ax.set_title('Phase-folded')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbd68a-2bd7-4b99-91f0-5acd13a95629",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 800px; margin: 0 auto; text-align: justify;\">\n",
    "    \n",
    "-----------\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- **Betancourt (2018)**, \"A Conceptual Introduction to Hamiltonian Monte Carlo\" ‚Äî ¬ß1‚Äì2: Typical set. ¬ß3: Hamiltonian dynamics. ¬ß4‚Äì5: Implementation. ¬ß6: Diagnostics.\n",
    "- **Hogg & Foreman-Mackey (2018)**, \"Data Analysis Recipes: Using Markov Chain Monte Carlo\" ‚Äî ¬ß3: Metropolis. ¬ß5: Convergence. ¬ß6: Tuning. ¬ß9: Troubleshooting.\n",
    "- **Sharma (2017)**, \"MCMC Methods for Bayesian Data Analysis in Astronomy\" ‚Äî ¬ß3.7: Convergence. ¬ß3.10: HMC.\n",
    "- **Foreman-Mackey et al. (2013)**, \"emcee: The MCMC Hammer\"\n",
    "- **Hoffman & Gelman (2014)**, \"The No-U-Turn Sampler\"\n",
    "\n",
    "-----------\n",
    " </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
